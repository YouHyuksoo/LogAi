"""
@file backend/app/api/api_v1/endpoints/chat.py
@description
ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì±„íŒ… API ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
ClickHouse ë¡œê·¸ ê²€ìƒ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , vLLMì„ ì‚¬ìš©í•˜ì—¬ AI ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. **POST /chat**: ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„±
2. ë¡œê·¸ ê²€ìƒ‰: ClickHouseì—ì„œ ì§ˆë¬¸ ê´€ë ¨ ë¡œê·¸ ê²€ìƒ‰
3. vLLM ì¶”ë¡ : ê²€ìƒ‰ëœ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

ì´ˆë³´ì ê°€ì´ë“œ:
- **message**: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "ìµœê·¼ API ì„œë²„ ì¥ì•  ì›ì¸ì€?")
- **history**: ì´ì „ ëŒ€í™” ë‚´ì—­ (ì„ íƒì‚¬í•­, ë¬¸ë§¥ ìœ ì§€ìš©)
- **response**: AIê°€ ìƒì„±í•œ ë‹µë³€ (Markdown í˜•ì‹)
- **sources**: ì°¸ì¡°í•œ ë¡œê·¸ í•­ëª©ë“¤

@example
POST /api/v1/chat
{
  "message": "ìµœê·¼ API ì„œë²„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê¸‰ì¦í•œ ì´ìœ ëŠ”?",
  "history": []
}

Response:
{
  "response": "### ë¶„ì„ ê²°ê³¼\në©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ì˜ì‹¬ë©ë‹ˆë‹¤...",
  "sources": ["[2024-01-15T10:30:00Z] ERROR api-server: Memory usage...", "[2024-01-15T10:31:00Z] ERROR api-server: GC failure..."]
}
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from app.services.rag_engine import rag_engine
from app.services.llm_factory import llm_factory
from app.core.config import settings
import json

router = APIRouter()


# ==================== Helper Functions ====================

def extract_sql_query(llm_response: str) -> tuple[str, bool]:
    """
    LLM ì‘ë‹µì—ì„œ SQL ì¿¼ë¦¬ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜

    Args:
        llm_response: LLMì˜ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸

    Returns:
        tuple: (ì¶”ì¶œëœ SQL ë˜ëŠ” "NO_QUERY", ìœ íš¨í•œ SELECT ì¿¼ë¦¬ì¸ì§€ ì—¬ë¶€)

    ë™ì‘:
    1. ì½”ë“œë¸”ë¡(```sql ... ```) ì œê±°
    2. ê³µë°± ì •ë¦¬
    3. NO_QUERY ì²´í¬
    4. SELECTë¡œ ì‹œì‘í•˜ëŠ”ì§€ ê²€ì¦
    """
    if not llm_response:
        return "NO_QUERY", False

    # ì½”ë“œë¸”ë¡ ì œê±° (```sql, ```, ```SQL ë“±)
    cleaned = llm_response.strip()

    # ```sql ... ``` í˜•íƒœ ì²˜ë¦¬
    if "```" in cleaned:
        # ì½”ë“œë¸”ë¡ ë‚´ìš©ë§Œ ì¶”ì¶œ
        import re
        # ```sql ë˜ëŠ” ``` ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
        code_block_pattern = r'```(?:sql|SQL)?\s*([\s\S]*?)```'
        matches = re.findall(code_block_pattern, cleaned)
        if matches:
            cleaned = matches[0].strip()
        else:
            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì œê±°
            cleaned = cleaned.replace("```sql", "").replace("```SQL", "").replace("```", "").strip()

    # NO_QUERY ì²´í¬ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
    if cleaned.upper() == "NO_QUERY" or "NO_QUERY" in cleaned.upper():
        return "NO_QUERY", False

    # SELECTë¡œ ì‹œì‘í•˜ëŠ”ì§€ ê²€ì¦
    is_valid_select = cleaned.upper().startswith("SELECT")

    return cleaned, is_valid_select


# ==================== Request/Response Models ====================

class ChatMessage(BaseModel):
    """ì±„íŒ… ë©”ì‹œì§€ (í”„ë¡ íŠ¸ì—”ë“œ íˆìŠ¤í† ë¦¬ìš©)"""
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user/assistant)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")

class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­"""
    message: str = Field(..., description="ì‚¬ìš©ì ì§ˆë¬¸", min_length=1)
    history: Optional[List[ChatMessage]] = Field(default=[], description="ëŒ€í™” íˆìŠ¤í† ë¦¬")
    llm_provider: Optional[str] = Field(default=None, description="LLM ì œê³µì (local, openai, gemini)")

class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ"""
    response: str = Field(..., description="AI ì‘ë‹µ (Markdown)")
    sources: List[str] = Field(default=[], description="ì°¸ì¡°í•œ ì†ŒìŠ¤ ëª©ë¡")
    analysis_id: Optional[str] = Field(default=None, description="ë¶„ì„ ê²°ê³¼ ID (Qdrant ì €ì¥ìš©)")
    data_source: Optional[str] = Field(default=None, description="ë°ì´í„° ì¶œì²˜ (sql_query, recent_logs, general_knowledge)")
    data_source_detail: Optional[str] = Field(default=None, description="ë°ì´í„° ì¶œì²˜ ìƒì„¸ ì„¤ëª…")

# ==================== Endpoints ====================

@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„± (Text-to-SQL ê¸°ë°˜ ë¶„ì„)

    Flow:
    1. LLMì´ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ SQL ì¿¼ë¦¬ ìƒì„±
    2. ClickHouseì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
    3. ê²°ê³¼ë¥¼ LLMì´ ë¶„ì„í•˜ì—¬ ë‹µë³€ ìƒì„±
    4. AI ì‘ë‹µ ë°˜í™˜

    ì£¼ìš” ê°œì„ :
    - ëª¨ë“  ì§ˆë¬¸ ìœ í˜•ì„ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
    - ë¹ˆë„, ì›ì¸, íŒ¨í„´ ë“± ë‹¤ì–‘í•œ ë¶„ì„ ì§€ì›
    - LLMì´ í•„ìš”í•œ ë°ì´í„°ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨
    """
    try:
        # 1. LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = llm_factory.get_client(provider=request.llm_provider)

        # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        import os
        prompt_paths = [
            "app/core/system_prompt.md",
            "backend/app/core/system_prompt.md",
        ]
        system_persona = "ë‹¹ì‹ ì€ NPM SMT ë§ˆìš´í„° ë¡œê·¸ ë¶„ì„ ë° ì„¤ë¹„ ë¬¸ì œ í•´ê²°ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

        for prompt_path in prompt_paths:
            if os.path.exists(prompt_path):
                try:
                    with open(prompt_path, "r", encoding="utf-8") as f:
                        system_persona = f.read()
                    break
                except Exception:
                    pass

        # 3. ClickHouse í´ë¼ì´ì–¸íŠ¸
        from app.services.clickhouse_client import ch_client
        import re

        # ==================== ë¶„ì„ ê³¼ì • ë¡œê¹… ====================
        import json
        import time

        process_steps = []
        start_time = time.time()

        # ==================== STEP 1: LLMì´ SQL ì¿¼ë¦¬ ìƒì„± ====================
        print(f"ğŸ” Step 1: SQL ì¿¼ë¦¬ ìƒì„± ì‹œì‘ - '{request.message}'")
        step1_start = time.time()

        # ClickHouse ìŠ¤í‚¤ë§ˆ ì •ë³´ (LLMì—ê²Œ ì œê³µ)
        db_schema = """
### ClickHouse í…Œì´ë¸” êµ¬ì¡°:

**logs í…Œì´ë¸”** (ë¡œê·¸ ì €ì¥ì†Œ)
- timestamp: DateTime (ë¡œê·¸ ë°œìƒ ì‹œê°„)
- log_level: String (DEBUG, INFO, WARN, ERROR) âš ï¸ ì˜ë¬¸ë§Œ ì €ì¥ë¨!
- service: String (NPM/AM-04, NPM/AM-06 ë“±)
- template_id: UInt16 (Drain3 í…œí”Œë¦¿ ID)
- raw_message: String (ì›ë³¸ ë¡œê·¸ ë©”ì‹œì§€) âš ï¸ ì˜ë¬¸ ë¡œê·¸!

**anomalies í…Œì´ë¸”** (ì´ìƒ íƒì§€ ê²°ê³¼)
- timestamp: DateTime (íƒì§€ ì‹œê°„)
- template_id: UInt16 (í…œí”Œë¦¿ ID)
- anomaly_score: Float32 (ì´ìƒë„, 0.0~1.0)
- is_anomaly: UInt8 (1=ì´ìƒ, 0=ì •ìƒ)
- status: String (open, resolved, closed)

**analysis_results í…Œì´ë¸”** (ë¶„ì„ ê²°ê³¼)
- timestamp: DateTime (ë¶„ì„ ì‹œê°„)
- query: String (ì‚¬ìš©ì ì§ˆë¬¸)
- ai_response: String (AI ë‹µë³€)
- sources: Array(String) (ì°¸ì¡° ì†ŒìŠ¤)

### â­â­â­ ì¤‘ìš”: ë¡œê·¸ëŠ” ì˜ë¬¸, ì§ˆë¬¸ì€ í•œêµ­ì–´ â­â­â­
**ë¡œê·¸ ë°ì´í„°ëŠ” ëª¨ë‘ ì˜ë¬¸ì…ë‹ˆë‹¤!**
- ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•´ë„, SQLì˜ WHERE ì¡°ê±´ì—ëŠ” **ì˜ì–´ í‚¤ì›Œë“œ**ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆ: "ë…¸ì¦ ì—ëŸ¬" â†’ raw_message ILIKE '%nozzle%' AND log_level = 'ERROR'
- ì˜ˆ: "í”¼ë” ê²½ê³ " â†’ raw_message ILIKE '%feeder%' AND log_level = 'WARN'
- log_level ê°’: 'DEBUG', 'INFO', 'WARN', 'ERROR' (ì˜ë¬¸ ëŒ€ë¬¸ì)
- í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì ì ˆí•œ ì˜ì–´ë¡œ ë²ˆì—­í•´ì„œ ê²€ìƒ‰í•˜ì„¸ìš”.

### ClickHouse ì „ìš© í•¨ìˆ˜ (ë°˜ë“œì‹œ ì‚¬ìš©):
**ë°°ì—´/ì§‘ê³„ í•¨ìˆ˜:**
- groupArray(column): ë°°ì—´ë¡œ ê·¸ë£¹í™” (ì¤‘ë³µ í¬í•¨)
- groupUniqArray(column): ì¤‘ë³µ ì—†ëŠ” ë°°ì—´ë¡œ ê·¸ë£¹í™” â­ì¶”ì²œ
- COUNT(DISTINCT column): ì¤‘ë³µ ì œê±° ì¹´ìš´íŠ¸

**ì‹œê°„ í•¨ìˆ˜:**
- now(), yesterday(), today()
- toStartOfDay(timestamp), toStartOfHour(timestamp)
- toDate(timestamp), toDateTime(string)

ì˜ˆì‹œ ì¿¼ë¦¬:
- ë¹ˆë„: SELECT service, COUNT(*) as cnt FROM logs WHERE log_level='ERROR' GROUP BY service
- ì‹œê°„ëŒ€: SELECT toStartOfHour(timestamp) as hour, COUNT(*) FROM logs GROUP BY hour
- íŒ¨í„´: SELECT template_id, COUNT(*) FROM logs GROUP BY template_id ORDER BY COUNT(*) DESC
- ì„œë¹„ìŠ¤ ëª©ë¡: SELECT template_id, groupUniqArray(service) FROM logs GROUP BY template_id
"""

        # LLMì—ê²Œ SQL ìƒì„± ìš”ì²­
        sql_generation_prompt = f"""{db_schema}

ì‚¬ìš©ì ì§ˆë¬¸: "{request.message}"

ìœ„ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ClickHouse SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ì¤˜.

ê·œì¹™:
1. **ë‹¨ì¼ SELECT ì¿¼ë¦¬ë§Œ ì‘ì„±** (ì—¬ëŸ¬ ì¿¼ë¦¬ ê¸ˆì§€, ì„¸ë¯¸ì½œë¡  ì—¬ëŸ¬ ê°œ ì‚¬ìš© ê¸ˆì§€)
2. **ì£¼ì„ ê¸ˆì§€** (-- ì£¼ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ)
3. SELECT ë¬¸ë§Œ ì‘ì„± (INSERT, DELETE, DROP ê¸ˆì§€)
4. ClickHouse ë¬¸ë²• ì‚¬ìš©:
   - ì‹œê°„ í•¨ìˆ˜: now(), yesterday(), today()
   - ì‹œê°„ ì—°ì‚°: now() - INTERVAL 1 DAY (ì–´ì œ), now() - INTERVAL 7 DAY (ìµœê·¼ 7ì¼)
   - ë‚ ì§œ í•¨ìˆ˜: toStartOfDay(), toStartOfHour(), toDate()
5. LIMITì€ ìµœëŒ€ 100
6. ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê¸° ì‰½ê²Œ ORDER BY ì¶”ê°€
7. ì—¬ëŸ¬ ì •ë³´ê°€ í•„ìš”í•˜ë©´ JOINì„ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ì˜ ì¿¼ë¦¬ë¡œ í†µí•©
8. **â­ ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ê²€ìƒ‰**: í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ë°˜ë“œì‹œ ILIKE ì‚¬ìš©!
   - âŒ raw_message LIKE '%NOZZLE%' (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ë¨)
   - âœ… raw_message ILIKE '%nozzle%' (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ClickHouse ìµœì í™”)

ClickHouse ì‹œê°„ í•„í„° ì˜ˆì‹œ:
- ì–´ì œ: timestamp >= yesterday() AND timestamp < today()
- ìµœê·¼ 24ì‹œê°„: timestamp >= now() - INTERVAL 24 HOUR
- ìµœê·¼ 7ì¼: timestamp >= now() - INTERVAL 7 DAY

ì‘ë‹µ í˜•ì‹:
```sql
SELECT ...
```

ë°˜ë“œì‹œ í•˜ë‚˜ì˜ SELECT ì¿¼ë¦¬ë§Œ ì‘ì„±í•  ê²ƒ. ì¿¼ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë©´ "NO_QUERY" ë¼ê³ ë§Œ ë‹µë³€"""

        sql_response = await client.chat.completions.create(
            model=llm_factory.get_model_name(provider=request.llm_provider),
            messages=[{"role": "user", "content": sql_generation_prompt}],
            temperature=0.1,  # ì¿¼ë¦¬ëŠ” ì •í™•í•˜ê²Œ
            max_tokens=500
        )

        raw_sql_response = sql_response.choices[0].message.content.strip()
        sql_query, is_valid_sql = extract_sql_query(raw_sql_response)
        print(f"ğŸ“ ìƒì„±ëœ ì¿¼ë¦¬ (ì›ë³¸):\n{raw_sql_response}")
        print(f"ğŸ“ ì¶”ì¶œëœ ì¿¼ë¦¬:\n{sql_query}")
        print(f"ğŸ“ ìœ íš¨í•œ SELECT: {is_valid_sql}")

        process_steps.append({
            "step": "SQL_GENERATION",
            "duration_ms": round((time.time() - step1_start) * 1000),
            "generated_sql": sql_query,
            "raw_response": raw_sql_response,
            "is_valid_sql": is_valid_sql,
            "status": "success"
        })

        # ==================== STEP 2: SQL ì‹¤í–‰ ====================
        query_data = None
        sql_execution_success = False
        step2_start = time.time()

        print(f"ğŸ” Step 2: SQL ì‹¤í–‰ - ì¿¼ë¦¬: {sql_query[:80]}...")

        if sql_query != "NO_QUERY" and is_valid_sql:
            print(f"âœ… SELECT ì¿¼ë¦¬ í™•ì¸ë¨, ë³´ì•ˆ ê²€ì‚¬ ì§„í–‰")
            # ê¸°ë³¸ ë³´ì•ˆ: ìœ„í—˜í•œ ëª…ë ¹ì–´ ì²´í¬
            dangerous_keywords = ["DROP", "DELETE", "INSERT", "UPDATE", "ALTER", "TRUNCATE"]
            is_safe = not any(kw in sql_query.upper() for kw in dangerous_keywords)

            if is_safe:
                try:
                    print(f"âœ… SQL ê²€ì¦ í†µê³¼, ì‹¤í–‰ ì¤‘...")
                    # ==================== STEP 3: ClickHouse ì‹¤í–‰ ====================
                    # sql_queryëŠ” ì´ë¯¸ extract_sql_query()ì—ì„œ ì •ë¦¬ëœ ìƒíƒœ
                    query_data = ch_client.execute(sql_query)
                    sql_execution_success = True
                    print(f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ, {len(query_data) if query_data else 0}ê°œ í–‰ ë°˜í™˜")

                    process_steps.append({
                        "step": "SQL_EXECUTION",
                        "duration_ms": round((time.time() - step2_start) * 1000),
                        "success": True,
                        "rows_returned": len(query_data) if query_data else 0
                    })
                except Exception as e:
                    error_message = str(e)
                    print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {error_message}")

                    # ==================== STEP 3.5: ì˜¤ë¥˜ ë°œìƒ ì‹œ LLMì—ê²Œ ì¬ì‹œë„ ìš”ì²­ ====================
                    print(f"ğŸ”„ Step 3.5: LLMì—ê²Œ ì˜¤ë¥˜ ìˆ˜ì • ìš”ì²­")
                    step3_5_start = time.time()

                    retry_prompt = f"""ë‹¤ìŒ SQL ì¿¼ë¦¬ê°€ ClickHouseì—ì„œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´. ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì¤˜.

ì‹¤íŒ¨í•œ ì¿¼ë¦¬:
{sql_query}

ì˜¤ë¥˜ ë©”ì‹œì§€:
{error_message}

ì¼ë°˜ì ì¸ ClickHouse ì˜¤ë¥˜ í•´ê²° ë°©ë²•:
1. GROUP BY ë¬¸ì œ: SELECTì— ìˆëŠ” ëª¨ë“  non-aggregate ì»¬ëŸ¼ì€ GROUP BYì— í¬í•¨ë˜ì–´ì•¼ í•¨
2. LEFT JOIN NULL ë¬¸ì œ: JOINëœ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì„ GROUP BYì— ë„£ì§€ ë§ê³ , MAX() ë“± ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš©
3. ë°°ì—´ í•¨ìˆ˜: groupUniqArray() ì‚¬ìš© ì‹œ ë„ˆë¬´ ë§ì€ ë°ì´í„°ëŠ” ì œí•œ í•„ìš”
4. LIKE ê²€ìƒ‰: ëŒ€ì†Œë¬¸ì êµ¬ë¶„í•¨, í•„ìš”ì‹œ lower() ì‚¬ìš©
5. í•¨ìˆ˜ ì˜¤ë¥˜:
   - âŒ toIntervalDay(N) â†’ âœ… INTERVAL N DAY
   - âŒ greatest(a, b) â†’ âœ… if(a > b, a, b) ë˜ëŠ” max(a, b)
   - âŒ least(a, b) â†’ âœ… if(a < b, a, b) ë˜ëŠ” min(a, b)
6. ì„œë¸Œì¿¼ë¦¬ ë‹¨ìˆœí™”: ë„ˆë¬´ ë³µì¡í•œ JOINì€ ë‹¨ìˆœí•œ ì¿¼ë¦¬ë¡œ ë¶„ë¦¬

ìˆ˜ì •ëœ ì¿¼ë¦¬ë§Œ ë°˜í™˜ (ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ SQLë§Œ):
SELECT ...

ì¶”ê°€ ì„¤ëª… ì—†ì´ ì¿¼ë¦¬ë§Œ ë°˜í™˜í•  ê²ƒ."""

                    try:
                        retry_response = await client.chat.completions.create(
                            model=llm_factory.get_model_name(provider=request.llm_provider),
                            messages=[{"role": "user", "content": retry_prompt}],
                            temperature=0.0,
                            max_tokens=500
                        )

                        raw_fixed_response = retry_response.choices[0].message.content.strip()
                        fixed_query, is_valid_fixed = extract_sql_query(raw_fixed_response)
                        print(f"ğŸ”§ ìˆ˜ì •ëœ ì¿¼ë¦¬:\n{fixed_query}")
                        print(f"ğŸ”§ ìœ íš¨í•œ SELECT: {is_valid_fixed}")

                        # ìˆ˜ì •ëœ ì¿¼ë¦¬ ì¬ì‹¤í–‰
                        try:
                            query_data = ch_client.execute(fixed_query)
                            sql_execution_success = True
                            print(f"âœ… ì¬ì‹œë„ ì„±ê³µ! {len(query_data) if query_data else 0}ê°œ í–‰ ë°˜í™˜")

                            process_steps.append({
                                "step": "SQL_RETRY_AFTER_ERROR",
                                "duration_ms": round((time.time() - step3_5_start) * 1000),
                                "original_error": error_message,
                                "fixed_sql": fixed_query,
                                "success": True,
                                "rows_returned": len(query_data) if query_data else 0
                            })
                        except Exception as retry_error:
                            print(f"âŒ ì¬ì‹œë„ë„ ì‹¤íŒ¨: {retry_error}")
                            query_data = None
                            process_steps.append({
                                "step": "SQL_RETRY_AFTER_ERROR",
                                "duration_ms": round((time.time() - step3_5_start) * 1000),
                                "original_error": error_message,
                                "fixed_sql": fixed_query,
                                "retry_error": str(retry_error),
                                "success": False
                            })
                    except Exception as llm_error:
                        print(f"âŒ LLM ì¬ì‹œë„ ìš”ì²­ ì‹¤íŒ¨: {llm_error}")
                        query_data = None

                    # ìµœì¢… ì‹¤íŒ¨ ê¸°ë¡ (ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ)
                    if not sql_execution_success:
                        process_steps.append({
                            "step": "SQL_EXECUTION",
                            "duration_ms": round((time.time() - step2_start) * 1000),
                            "success": False,
                            "error": error_message
                        })
            else:
                print(f"âš ï¸ ìœ„í—˜í•œ SQL ê°ì§€, ì‹¤í–‰ ë°©ì§€")
                process_steps.append({
                    "step": "SQL_VALIDATION",
                    "duration_ms": round((time.time() - step2_start) * 1000),
                    "success": False,
                    "reason": "Dangerous keywords detected"
                })
                query_data = None
        else:
            # NO_QUERYì´ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ SQLì¸ ê²½ìš°
            print(f"âš ï¸ SQL ì‹¤í–‰ ë¶ˆê°€: sql_query={sql_query[:50] if sql_query != 'NO_QUERY' else 'NO_QUERY'}")
            print(f"   - NO_QUERY ì—¬ë¶€: {sql_query == 'NO_QUERY'}")
            print(f"   - ìœ íš¨í•œ SELECT: {is_valid_sql}")
            query_data = None

        # ==================== STEP 4: ê²°ê³¼ ë¶„ì„ ====================
        context = f"ì‚¬ìš©ì ì§ˆë¬¸: {request.message}\n\n"

        # â­ ë°ì´í„° ì¶œì²˜ ì¶”ì  ë³€ìˆ˜
        data_source = "unknown"  # sql_query, recent_logs, general_knowledge
        data_source_detail = ""
        query_rows_count = len(query_data) if query_data else 0

        # SQL ì‹¤í–‰ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ì¶œ
        sql_error_message = None
        for step in process_steps:
            if step.get("step") == "SQL_EXECUTION" and not step.get("success"):
                sql_error_message = step.get("error")
                break
            if step.get("step") == "SQL_RETRY_AFTER_ERROR" and not step.get("success"):
                sql_error_message = step.get("retry_error")
                break

        # â­ í•µì‹¬ ìˆ˜ì •: sql_execution_success í”Œë˜ê·¸ë¡œ íŒë‹¨ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ []ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬)
        if sql_execution_success:
            if query_data:
                # SQL ì‹¤í–‰ ì„±ê³µ + ë°ì´í„° ìˆìŒ â†’ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·
                data_source = "sql_query"
                data_source_detail = f"SQL ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ ({query_rows_count}ê°œ í–‰)"
                data_text = f"ğŸ“Š [ë°ì´í„° ì¶œì²˜: SQL ì¿¼ë¦¬ ê²°ê³¼ - {query_rows_count}ê°œ í–‰]\n\nì¿¼ë¦¬ ê²°ê³¼:\n"
                for i, row in enumerate(query_data[:20]):  # ìµœëŒ€ 20í–‰ë§Œ í‘œì‹œ
                    data_text += f"{i+1}. {row}\n"
                context += data_text
            else:
                # SQL ì‹¤í–‰ ì„±ê³µ + ë°ì´í„° ì—†ìŒ (0í–‰ ë°˜í™˜) â†’ ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ ë‹µë³€
                data_source = "general_knowledge"
                data_source_detail = f"SQL ì¿¼ë¦¬ ì„±ê³µí–ˆìœ¼ë‚˜ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„° ì—†ìŒ (0ê°œ í–‰). ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ ë‹µë³€."
                context += f"âš ï¸ [ë°ì´í„° ì¶œì²˜: ì¼ë°˜ ì§€ì‹ ê¸°ë°˜]\n\n"
                context += f"SQL ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆì§€ë§Œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ 0ê±´ì…ë‹ˆë‹¤.\n"
                context += f"ì‹¤í–‰ëœ ì¿¼ë¦¬: {sql_query}\n"
                context += f"\nâ†’ í•´ë‹¹ í‚¤ì›Œë“œ/ì¡°ê±´ì— ë§ëŠ” ë¡œê·¸ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                context += f"â†’ ì•„ë˜ ë‹µë³€ì€ ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹Œ ì¼ë°˜ì ì¸ ë„ë©”ì¸ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n"
        elif sql_query != "NO_QUERY":
            # SQLì€ ìƒì„±ë˜ì—ˆëŠ”ë° ì‹¤í–‰ ì‹¤íŒ¨ â†’ ìµœê·¼ ë¡œê·¸ ë˜ëŠ” ì¼ë°˜ ì§€ì‹ ê¸°ë°˜
            data_source = "recent_logs"
            data_source_detail = f"SQL ì‹¤í–‰ ì‹¤íŒ¨ë¡œ ìµœê·¼ ë¡œê·¸ ê¸°ë°˜ ë¶„ì„"
            context += f"âš ï¸ [ë°ì´í„° ì¶œì²˜: ìµœê·¼ ë¡œê·¸ + ì¼ë°˜ ì§€ì‹]\n\n"
            context += f"SQL ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ë¡œ ìµœê·¼ ë¡œê·¸ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.\n"
            context += f"ìƒì„±ëœ ì¿¼ë¦¬: {sql_query}\n"
            if sql_error_message:
                context += f"ì˜¤ë¥˜: {sql_error_message[:200]}...\n\n"
        else:
            # SQLì„ ìƒì„±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° â†’ ìµœê·¼ ë¡œê·¸ ì‚¬ìš©
            data_source = "recent_logs"
            data_source_detail = "SQL ìƒì„± ë¶ˆê°€ë¡œ ìµœê·¼ ë¡œê·¸ ê¸°ë°˜ ë¶„ì„"
            context += f"â„¹ï¸ [ë°ì´í„° ì¶œì²˜: ìµœê·¼ ë¡œê·¸]\n\n"
            context += "ì´ ì§ˆë¬¸ì€ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ì–´ ìµœê·¼ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.\n"
            try:
                log_query = "SELECT timestamp, log_level, service, raw_message FROM logs ORDER BY timestamp DESC LIMIT 10"
                log_result = ch_client.execute(log_query)
                context += "\nìµœê·¼ ë¡œê·¸:\n"
                for row in log_result:
                    context += f"[{row[0]}] {row[1]} {row[2]}: {row[3]}\n"
            except Exception as e:
                print(f"ìµœê·¼ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ìµœê·¼ ë¡œê·¸ë„ ì¶”ê°€ (ë°°ê²½ ì •ë³´)
        recent_logs = []
        try:
            log_query = "SELECT timestamp, log_level, service, raw_message FROM logs ORDER BY timestamp DESC LIMIT 10"
            log_result = ch_client.execute(log_query)
            recent_logs = [
                f"[{row[0]}] {row[1]} {row[2]}: {row[3]}"
                for row in log_result
            ]
        except Exception as e:
            print(f"ìµœê·¼ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ==================== STEP 5: LLMì´ ìµœì¢… ë‹µë³€ ìƒì„± ====================
        print(f"ğŸ¤– Step 5: ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
        print(f"ğŸ“Œ ë°ì´í„° ì¶œì²˜: {data_source} - {data_source_detail}")

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
        messages = [{"role": "system", "content": system_persona}]

        if request.history:
            for msg in request.history[-5:]:  # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ í¬í•¨
                messages.append({"role": msg.role, "content": msg.content})

        # â­ ë°ì´í„° ì¶œì²˜ì— ë”°ë¥¸ LLM í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
        if data_source == "sql_query":
            # SQL ê²°ê³¼ ê¸°ë°˜ â†’ ë°ì´í„° ê¸°ë°˜ ë¶„ì„
            final_prompt = f"""{context}

ìœ„ SQL ì¿¼ë¦¬ ê²°ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.
- ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ì´ë¯€ë¡œ êµ¬ì²´ì ì¸ ìˆ«ìì™€ í†µê³„ë¡œ ì„¤ëª…
- íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œê°€ ìˆìœ¼ë©´ ë¶„ì„ ê²°ê³¼ ì œì‹œ
- ë‹µë³€ ì‹œì‘ì— "ğŸ“Š **[SQL ì¿¼ë¦¬ ê²°ê³¼ ê¸°ë°˜ ë¶„ì„]**" í‘œì‹œ"""
        elif data_source == "general_knowledge":
            # ë°ì´í„° ì—†ìŒ â†’ ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ ë‹µë³€ (ëª…í™•íˆ ê³ ì§€)
            final_prompt = f"""{context}

âš ï¸ ì¤‘ìš”: SQL ì¿¼ë¦¬ëŠ” ì„±ê³µí–ˆì§€ë§Œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (0ê°œ í–‰).
ì‹¤ì œ ë¡œê·¸ ë°ì´í„°ê°€ ì•„ë‹Œ ì¼ë°˜ì ì¸ ë„ë©”ì¸ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ë°˜ë“œì‹œ ë‹µë³€ ì‹œì‘ì— "âš ï¸ **[ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ ë‹µë³€]** - ì¡°ê±´ì— ë§ëŠ” ë¡œê·¸ ë°ì´í„°ê°€ ì—†ì–´ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤." í‘œì‹œ
2. ì¶”ì¸¡ì„± ë‚´ìš©ì€ "~ë¡œ ì¶”ì •ë©ë‹ˆë‹¤", "~ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"ë¡œ í‘œí˜„
3. ê°€ëŠ¥í•˜ë‹¤ë©´ ë°ì´í„°ê°€ ì—†ëŠ” ì´ìœ (ë¡œê·¸ ë¯¸ìˆ˜ì§‘, í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜ ë“±) ì„¤ëª…
4. í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ ì œì•ˆ"""
        else:
            # ìµœê·¼ ë¡œê·¸ ê¸°ë°˜
            final_prompt = f"""{context}

ìœ„ ìµœê·¼ ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.
- SQL ì¿¼ë¦¬ê°€ ì‹¤íŒ¨í•˜ê±°ë‚˜ ìƒì„±ë˜ì§€ ì•Šì•„ ìµœê·¼ ë¡œê·¸ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤
- ë‹µë³€ ì‹œì‘ì— "ğŸ“‹ **[ìµœê·¼ ë¡œê·¸ ê¸°ë°˜ ë¶„ì„]**" í‘œì‹œ
- ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ë¶„ì„ ì œê³µ"""

        messages.append({"role": "user", "content": final_prompt})

        # LLM í˜¸ì¶œ
        model_name = llm_factory.get_model_name(provider=request.llm_provider)

        response = await client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.3,
            max_tokens=1024
        )

        ai_response = response.choices[0].message.content
        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")

        # ==================== STEP 6: Sources ìƒì„± ====================
        sources = []
        if query_data:
            # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ sourcesë¡œ ì‚¬ìš©
            for i, row in enumerate(query_data[:3]):
                sources.append(f"ë°ì´í„° í–‰ {i+1}: {row}")
        elif recent_logs:
            # Fallback: ìµœê·¼ ë¡œê·¸
            for log_entry in recent_logs[:3]:
                sources.append(log_entry)
        else:
            sources = ["ì‹¤ì‹œê°„ ë¡œê·¸ ê¸°ë°˜ ë¶„ì„"]

        # ==================== STEP 7: ë¶„ì„ ê²°ê³¼ ì €ì¥ ====================
        analysis_id = None
        try:
            llm_provider_used = request.llm_provider or settings.LLM_PROVIDER

            # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
            sql_execution_result_json = None
            if query_data:
                try:
                    # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    result_list = [list(row) if hasattr(row, '__iter__') else str(row) for row in query_data[:20]]
                    sql_execution_result_json = json.dumps(result_list, ensure_ascii=False, default=str)
                except Exception as e:
                    print(f"âš ï¸ ì¿¼ë¦¬ ê²°ê³¼ ì§ë ¬í™” ì‹¤íŒ¨: {e}")
                    sql_execution_result_json = None

            # ì „ì²´ ê³¼ì • ë¡œê·¸ë¥¼ JSONìœ¼ë¡œ
            process_steps.append({
                "step": "TOTAL_PROCESS",
                "total_duration_ms": round((time.time() - start_time) * 1000),
                "timestamp": json.loads(json.dumps({"now": str(time.time())}, default=str))["now"]
            })

            process_log_json = json.dumps(process_steps, ensure_ascii=False, default=str)

            analysis_id = ch_client.insert_analysis(
                query=request.message,
                keywords=[],  # Text-to-SQL ë°©ì‹ì—ì„œëŠ” í‚¤ì›Œë“œ ë¶ˆí•„ìš”
                log_context=context[:5000],
                llm_prompt=final_prompt,  # LLMì—ê²Œ ë³´ë‚¸ ìµœì¢… í”„ë¡¬í”„íŠ¸
                ai_response=ai_response,
                llm_provider=llm_provider_used,
                sources=sources,
                generated_sql=sql_query if sql_query != "NO_QUERY" else None,
                sql_execution_success=sql_execution_success,
                sql_execution_result=sql_execution_result_json,
                process_log=process_log_json
            )
            print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ID: {analysis_id})")
            print(f"ğŸ“Š ë¶„ì„ ê³¼ì •: {process_log_json}")
        except Exception as save_error:
            print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_error}")

        return ChatResponse(
            response=ai_response,
            sources=sources,
            analysis_id=analysis_id,
            data_source=data_source,
            data_source_detail=data_source_detail
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@router.get("/health")
def chat_health():
    """ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "service": "chat"}


@router.get("/history")
def get_analysis_history(limit: int = 20):
    """
    ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (Text-to-SQL ê³¼ì • í¬í•¨)

    Args:
        limit: ì¡°íšŒí•  ê°œìˆ˜ (ê¸°ë³¸ê°’: 20)

    Returns:
        ë¶„ì„ ê²°ê³¼ ëª©ë¡
    """
    from app.services.clickhouse_client import ch_client

    try:
        query = f"""
            SELECT id, timestamp, query, keywords, ai_response, llm_provider, sources,
                   generated_sql, sql_execution_success, sql_execution_result, process_log, llm_prompt
            FROM analysis_results
            ORDER BY timestamp DESC
            LIMIT {int(limit)}
        """
        results = ch_client.execute(query)

        return [
            {
                "id": str(row[0]),
                "timestamp": row[1].isoformat() if row[1] else None,
                "query": row[2],
                "keywords": row[3],
                "ai_response": row[4][:500] + "..." if len(row[4]) > 500 else row[4],
                "llm_provider": row[5],
                "sources": row[6],
                "generated_sql": row[7],
                "sql_execution_success": bool(row[8]),
                "sql_execution_result": row[9],
                "process_log": row[10],
                "llm_prompt": row[11]
            }
            for row in results
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch history: {str(e)}")


@router.get("/history/{analysis_id}")
def get_analysis_detail(analysis_id: str):
    """
    ë¶„ì„ ìƒì„¸ ì¡°íšŒ (ì „ì²´ ê³¼ì • í¬í•¨)

    Args:
        analysis_id: ë¶„ì„ ID (UUID)

    Returns:
        ë¶„ì„ ìƒì„¸ ì •ë³´ (ì§ˆë¬¸, ìƒì„±ëœ SQL, ì‹¤í–‰ ê²°ê³¼, ìµœì¢… ë‹µë³€, ê³¼ì • ë¡œê·¸)
    """
    from app.services.clickhouse_client import ch_client

    try:
        query = f"""
            SELECT id, timestamp, query, keywords, log_context, ai_response, llm_provider, sources,
                   generated_sql, sql_execution_success, sql_execution_result, process_log, llm_prompt
            FROM analysis_results
            WHERE id = '{analysis_id}'
            LIMIT 1
        """
        results = ch_client.execute(query)

        if not results:
            raise HTTPException(status_code=404, detail="Analysis not found")

        row = results[0]

        # process_log JSON íŒŒì‹± ì‹œë„
        process_log_data = None
        try:
            if row[11]:
                process_log_data = json.loads(row[11])
        except Exception:
            process_log_data = None

        # sql_execution_result JSON íŒŒì‹± ì‹œë„
        sql_result_data = None
        try:
            if row[10]:
                sql_result_data = json.loads(row[10])
        except Exception:
            sql_result_data = row[10]

        return {
            "id": str(row[0]),
            "timestamp": row[1].isoformat() if row[1] else None,
            "query": row[2],
            "keywords": row[3],
            "log_context": row[4],
            "ai_response": row[5],
            "llm_provider": row[6],
            "sources": row[7],
            "generated_sql": row[8],
            "sql_execution_success": bool(row[9]),
            "sql_execution_result": sql_result_data,
            "process_log": process_log_data,
            "llm_prompt": row[12],  # LLMì—ê²Œ ë³´ë‚¸ í”„ë¡¬í”„íŠ¸
            "analysis_summary": {
                "total_steps": len(process_log_data) if process_log_data else 0,
                "sql_used": bool(row[8]),
                "sql_success": bool(row[9])
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch analysis: {str(e)}")


@router.delete("/history/{analysis_id}")
def delete_analysis(analysis_id: str):
    """
    ë¶„ì„ íˆìŠ¤í† ë¦¬ ì‚­ì œ

    ClickHouseì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    ì£¼ì˜: ClickHouseëŠ” DELETEê°€ ë¹„ìš©ì´ í° ì‘ì—…ì´ë¯€ë¡œ
    ALTER TABLE ... DELETE ë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        analysis_id: ì‚­ì œí•  ë¶„ì„ ID (UUID)

    Returns:
        ì‚­ì œ ê²°ê³¼ ë©”ì‹œì§€
    """
    from app.services.clickhouse_client import ch_client

    try:
        # UUID í˜•ì‹ ê²€ì¦ (SQL ì¸ì ì…˜ ë°©ì§€)
        import re
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', analysis_id):
            raise HTTPException(status_code=400, detail="Invalid analysis ID format")

        # ë¨¼ì € ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        check_query = f"""
            SELECT count(*) FROM analysis_results
            WHERE id = '{analysis_id}'
        """
        check_result = ch_client.execute(check_query)

        if not check_result or check_result[0][0] == 0:
            raise HTTPException(status_code=404, detail="Analysis not found")

        # ClickHouseì—ì„œ ì‚­ì œ (ALTER TABLE ... DELETE ì‚¬ìš©)
        delete_query = f"""
            ALTER TABLE analysis_results
            DELETE WHERE id = '{analysis_id}'
        """
        ch_client.execute(delete_query)

        return {
            "success": True,
            "message": f"ë¶„ì„ ê²°ê³¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {analysis_id})"
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete analysis: {str(e)}")


@router.delete("/history")
def delete_all_analysis():
    """
    ì „ì²´ ë¶„ì„ íˆìŠ¤í† ë¦¬ ì‚­ì œ

    ClickHouseì—ì„œ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    ì£¼ì˜: ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!

    Returns:
        ì‚­ì œëœ í•­ëª© ìˆ˜
    """
    from app.services.clickhouse_client import ch_client

    try:
        # ì‚­ì œ ì „ ê°œìˆ˜ í™•ì¸
        count_query = "SELECT count(*) FROM analysis_results"
        count_result = ch_client.execute(count_query)
        total_count = count_result[0][0] if count_result else 0

        if total_count == 0:
            return {
                "success": True,
                "deleted_count": 0,
                "message": "ì‚­ì œí•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # TRUNCATE TABLE ì‚¬ìš© (ì „ì²´ ì‚­ì œì— ë” íš¨ìœ¨ì )
        truncate_query = "TRUNCATE TABLE analysis_results"
        ch_client.execute(truncate_query)

        return {
            "success": True,
            "deleted_count": total_count,
            "message": f"ì „ì²´ {total_count}ê°œì˜ ë¶„ì„ ê²°ê³¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete all analysis: {str(e)}")


# ==================== ì˜µì…˜ B: ìˆ˜ë™ Qdrant ì €ì¥ API ====================

class SaveToQdrantRequest(BaseModel):
    """Qdrant ì €ì¥ ìš”ì²­"""
    analysis_id: str = Field(..., description="ì €ì¥í•  ë¶„ì„ ID (ClickHouse)")
    title: Optional[str] = Field(default=None, description="ì‚¬ë¡€ ì œëª© (ì—†ìœ¼ë©´ ìë™ ìƒì„±)")


class SaveToQdrantResponse(BaseModel):
    """Qdrant ì €ì¥ ì‘ë‹µ"""
    success: bool = Field(..., description="ì €ì¥ ì„±ê³µ ì—¬ë¶€")
    qdrant_id: Optional[str] = Field(default=None, description="ì €ì¥ëœ Qdrant ë¬¸ì„œ ID")
    message: str = Field(..., description="ê²°ê³¼ ë©”ì‹œì§€")


@router.post("/save-to-qdrant", response_model=SaveToQdrantResponse)
async def save_analysis_to_qdrant(request: SaveToQdrantRequest):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ìˆ˜ë™ ì €ì¥ (ì˜µì…˜ B)

    ì‚¬ìš©ìê°€ ìœ ìš©í•˜ë‹¤ê³  íŒë‹¨í•œ ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ì €ì¥í•˜ì—¬
    í–¥í›„ ìœ ì‚¬ ì§ˆë¬¸ ì‹œ RAG ê²€ìƒ‰ì— í™œìš©í•©ë‹ˆë‹¤.

    Args:
        request: ì €ì¥ ìš”ì²­ (analysis_id í•„ìˆ˜)

    Returns:
        ì €ì¥ ê²°ê³¼ (success, qdrant_id, message)
    """
    from app.services.clickhouse_client import ch_client
    from app.services.rag_engine import rag_engine

    try:
        # 1. ClickHouseì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        query = f"""
            SELECT id, query, keywords, ai_response, llm_provider, sources
            FROM analysis_results
            WHERE id = '{request.analysis_id}'
            LIMIT 1
        """
        results = ch_client.execute(query)

        if not results:
            raise HTTPException(status_code=404, detail="Analysis not found")

        row = results[0]
        analysis_query = row[1]
        keywords = row[2] if row[2] else []
        ai_response = row[3]
        llm_provider = row[4]
        sources = row[5] if row[5] else []

        # 2. ì œëª© ìƒì„± (ì—†ìœ¼ë©´ ì§ˆë¬¸ ê¸°ë°˜ ìë™ ìƒì„±)
        title = request.title
        if not title:
            # ì§ˆë¬¸ì—ì„œ ì œëª© ì¶”ì¶œ (ìµœëŒ€ 50ì)
            title = f"ì±„íŒ… ë¶„ì„: {analysis_query[:50]}"
            if len(analysis_query) > 50:
                title += "..."

        # 3. Qdrantì— ì €ì¥
        qdrant_id = await rag_engine.save_incident(
            title=title,
            content=ai_response,
            incident_type="analysis",
            keywords=keywords,
            source="chat",
            metadata={
                "original_query": analysis_query,
                "llm_provider": llm_provider,
                "sources": sources,
                "analysis_id": request.analysis_id
            }
        )

        return SaveToQdrantResponse(
            success=True,
            qdrant_id=qdrant_id,
            message=f"ë¶„ì„ ê²°ê³¼ê°€ Qdrantì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {qdrant_id})"
        )

    except HTTPException:
        raise
    except Exception as e:
        return SaveToQdrantResponse(
            success=False,
            qdrant_id=None,
            message=f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/qdrant-stats")
def get_qdrant_stats():
    """
    Qdrant ì €ì¥ í˜„í™© ì¡°íšŒ

    Returns:
        ì €ì¥ëœ ì‚¬ë¡€ ìˆ˜ ë° ìƒíƒœ ì •ë³´
    """
    from app.services.rag_engine import rag_engine

    try:
        count = rag_engine.get_incident_count()
        return {
            "collection_name": rag_engine.collection_name,
            "total_documents": count,
            "vector_size": rag_engine.vector_size,
            "status": "healthy"
        }
    except Exception as e:
        return {
            "collection_name": "incident_manuals",
            "total_documents": 0,
            "vector_size": 0,
            "status": f"error: {str(e)}"
        }
