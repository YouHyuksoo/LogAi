"""
@file backend/app/api/api_v1/endpoints/chat.py
@description
ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì±„íŒ… API ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
ClickHouse ë¡œê·¸ ê²€ìƒ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , vLLMì„ ì‚¬ìš©í•˜ì—¬ AI ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. **POST /chat**: ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„±
2. ë¡œê·¸ ê²€ìƒ‰: ClickHouseì—ì„œ ì§ˆë¬¸ ê´€ë ¨ ë¡œê·¸ ê²€ìƒ‰
3. vLLM ì¶”ë¡ : ê²€ìƒ‰ëœ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

ì´ˆë³´ì ê°€ì´ë“œ:
- **message**: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "ìµœê·¼ API ì„œë²„ ì¥ì•  ì›ì¸ì€?")
- **history**: ì´ì „ ëŒ€í™” ë‚´ì—­ (ì„ íƒì‚¬í•­, ë¬¸ë§¥ ìœ ì§€ìš©)
- **response**: AIê°€ ìƒì„±í•œ ë‹µë³€ (Markdown í˜•ì‹)
- **sources**: ì°¸ì¡°í•œ ë¡œê·¸ í•­ëª©ë“¤

@example
POST /api/v1/chat
{
  "message": "ìµœê·¼ API ì„œë²„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê¸‰ì¦í•œ ì´ìœ ëŠ”?",
  "history": []
}

Response:
{
  "response": "### ë¶„ì„ ê²°ê³¼\në©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ì˜ì‹¬ë©ë‹ˆë‹¤...",
  "sources": ["[2024-01-15T10:30:00Z] ERROR api-server: Memory usage...", "[2024-01-15T10:31:00Z] ERROR api-server: GC failure..."]
}
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from app.services.rag_engine import rag_engine
from app.services.llm_factory import llm_factory
from app.core.config import settings
import json

router = APIRouter()

# ==================== Request/Response Models ====================

class ChatMessage(BaseModel):
    """ì±„íŒ… ë©”ì‹œì§€ (í”„ë¡ íŠ¸ì—”ë“œ íˆìŠ¤í† ë¦¬ìš©)"""
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user/assistant)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")

class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­"""
    message: str = Field(..., description="ì‚¬ìš©ì ì§ˆë¬¸", min_length=1)
    history: Optional[List[ChatMessage]] = Field(default=[], description="ëŒ€í™” íˆìŠ¤í† ë¦¬")
    llm_provider: Optional[str] = Field(default=None, description="LLM ì œê³µì (local, openai, gemini)")

class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ"""
    response: str = Field(..., description="AI ì‘ë‹µ (Markdown)")
    sources: List[str] = Field(default=[], description="ì°¸ì¡°í•œ ì†ŒìŠ¤ ëª©ë¡")
    analysis_id: Optional[str] = Field(default=None, description="ë¶„ì„ ê²°ê³¼ ID (Qdrant ì €ì¥ìš©)")

# ==================== Endpoints ====================

@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„± (Text-to-SQL ê¸°ë°˜ ë¶„ì„)

    Flow:
    1. LLMì´ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ SQL ì¿¼ë¦¬ ìƒì„±
    2. ClickHouseì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
    3. ê²°ê³¼ë¥¼ LLMì´ ë¶„ì„í•˜ì—¬ ë‹µë³€ ìƒì„±
    4. AI ì‘ë‹µ ë°˜í™˜

    ì£¼ìš” ê°œì„ :
    - ëª¨ë“  ì§ˆë¬¸ ìœ í˜•ì„ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
    - ë¹ˆë„, ì›ì¸, íŒ¨í„´ ë“± ë‹¤ì–‘í•œ ë¶„ì„ ì§€ì›
    - LLMì´ í•„ìš”í•œ ë°ì´í„°ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨
    """
    try:
        # 1. LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = llm_factory.get_client(provider=request.llm_provider)

        # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        import os
        prompt_paths = [
            "app/core/system_prompt.md",
            "backend/app/core/system_prompt.md",
        ]
        system_persona = "ë‹¹ì‹ ì€ NPM SMT ë§ˆìš´í„° ë¡œê·¸ ë¶„ì„ ë° ì„¤ë¹„ ë¬¸ì œ í•´ê²°ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

        for prompt_path in prompt_paths:
            if os.path.exists(prompt_path):
                try:
                    with open(prompt_path, "r", encoding="utf-8") as f:
                        system_persona = f.read()
                    break
                except Exception:
                    pass

        # 3. ClickHouse í´ë¼ì´ì–¸íŠ¸
        from app.services.clickhouse_client import ch_client
        import re

        # ==================== ë¶„ì„ ê³¼ì • ë¡œê¹… ====================
        import json
        import time

        process_steps = []
        start_time = time.time()

        # ==================== STEP 1: LLMì´ SQL ì¿¼ë¦¬ ìƒì„± ====================
        print(f"ğŸ” Step 1: SQL ì¿¼ë¦¬ ìƒì„± ì‹œì‘ - '{request.message}'")
        step1_start = time.time()

        # ClickHouse ìŠ¤í‚¤ë§ˆ ì •ë³´ (LLMì—ê²Œ ì œê³µ)
        db_schema = """
### ClickHouse í…Œì´ë¸” êµ¬ì¡°:

**logs í…Œì´ë¸”** (ë¡œê·¸ ì €ì¥ì†Œ)
- timestamp: DateTime (ë¡œê·¸ ë°œìƒ ì‹œê°„)
- log_level: String (DEBUG, INFO, WARN, ERROR)
- service: String (NPM/AM-04, NPM/AM-06 ë“±)
- template_id: UInt16 (Drain3 í…œí”Œë¦¿ ID)
- raw_message: String (ì›ë³¸ ë¡œê·¸ ë©”ì‹œì§€)

**anomalies í…Œì´ë¸”** (ì´ìƒ íƒì§€ ê²°ê³¼)
- timestamp: DateTime (íƒì§€ ì‹œê°„)
- template_id: UInt16 (í…œí”Œë¦¿ ID)
- anomaly_score: Float32 (ì´ìƒë„, 0.0~1.0)
- is_anomaly: UInt8 (1=ì´ìƒ, 0=ì •ìƒ)
- status: String (open, resolved, closed)

**analysis_results í…Œì´ë¸”** (ë¶„ì„ ê²°ê³¼)
- timestamp: DateTime (ë¶„ì„ ì‹œê°„)
- query: String (ì‚¬ìš©ì ì§ˆë¬¸)
- ai_response: String (AI ë‹µë³€)
- sources: Array(String) (ì°¸ì¡° ì†ŒìŠ¤)

ì˜ˆì‹œ ì¿¼ë¦¬:
- ë¹ˆë„: SELECT service, COUNT(*) as cnt FROM logs WHERE log_level='ERROR' GROUP BY service
- ì‹œê°„ëŒ€: SELECT toStartOfHour(timestamp) as hour, COUNT(*) FROM logs GROUP BY hour
- íŒ¨í„´: SELECT log_template, COUNT(*) FROM logs GROUP BY log_template ORDER BY COUNT(*) DESC
"""

        # LLMì—ê²Œ SQL ìƒì„± ìš”ì²­
        sql_generation_prompt = f"""{db_schema}

ì‚¬ìš©ì ì§ˆë¬¸: "{request.message}"

ìœ„ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ClickHouse SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ì¤˜.

ê·œì¹™:
1. SELECT ë¬¸ë§Œ ì‘ì„± (INSERT, DELETE, DROP ê¸ˆì§€)
2. ì‹œê°„ í•„í„°ëŠ” ìµœê·¼ 7ì¼ ê¸°ì¤€ (DATE_SUB(NOW(), INTERVAL 7 DAY))
3. LIMITì€ ìµœëŒ€ 100
4. ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê¸° ì‰½ê²Œ ORDER BY ì¶”ê°€

ì‘ë‹µ í˜•ì‹:
```sql
SELECT ...
```

ì¿¼ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë©´ "NO_QUERY" ë¼ê³ ë§Œ ë‹µë³€"""

        sql_response = await client.chat.completions.create(
            model=llm_factory.get_model_name(provider=request.llm_provider),
            messages=[{"role": "user", "content": sql_generation_prompt}],
            temperature=0.1,  # ì¿¼ë¦¬ëŠ” ì •í™•í•˜ê²Œ
            max_tokens=500
        )

        sql_query = sql_response.choices[0].message.content.strip()
        print(f"ğŸ“ ìƒì„±ëœ ì¿¼ë¦¬:\n{sql_query}")

        process_steps.append({
            "step": "SQL_GENERATION",
            "duration_ms": round((time.time() - step1_start) * 1000),
            "generated_sql": sql_query,
            "status": "success"
        })

        # ==================== STEP 2: SQL ê²€ì¦ ====================
        query_data = None
        sql_execution_success = False
        step2_start = time.time()

        if sql_query != "NO_QUERY" and sql_query.upper().startswith("SELECT"):
            # ê¸°ë³¸ ë³´ì•ˆ: ìœ„í—˜í•œ ëª…ë ¹ì–´ ì²´í¬
            dangerous_keywords = ["DROP", "DELETE", "INSERT", "UPDATE", "ALTER", "TRUNCATE"]
            is_safe = not any(kw in sql_query.upper() for kw in dangerous_keywords)

            if is_safe:
                try:
                    print(f"âœ… SQL ê²€ì¦ í†µê³¼, ì‹¤í–‰ ì¤‘...")
                    # ==================== STEP 3: ClickHouse ì‹¤í–‰ ====================
                    # SQLì—ì„œ ì½”ë“œë¸”ë¡ ë§ˆí¬ë‹¤ìš´ ì œê±°
                    clean_query = sql_query.replace("```sql", "").replace("```", "").strip()
                    query_data = ch_client.execute(clean_query)
                    sql_execution_success = True
                    print(f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ, {len(query_data) if query_data else 0}ê°œ í–‰ ë°˜í™˜")

                    process_steps.append({
                        "step": "SQL_EXECUTION",
                        "duration_ms": round((time.time() - step2_start) * 1000),
                        "success": True,
                        "rows_returned": len(query_data) if query_data else 0
                    })
                except Exception as e:
                    print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    query_data = None
                    process_steps.append({
                        "step": "SQL_EXECUTION",
                        "duration_ms": round((time.time() - step2_start) * 1000),
                        "success": False,
                        "error": str(e)
                    })
            else:
                print(f"âš ï¸ ìœ„í—˜í•œ SQL ê°ì§€, ì‹¤í–‰ ë°©ì§€")
                process_steps.append({
                    "step": "SQL_VALIDATION",
                    "duration_ms": round((time.time() - step2_start) * 1000),
                    "success": False,
                    "reason": "Dangerous keywords detected"
                })
                query_data = None

        # ==================== STEP 4: ê²°ê³¼ ë¶„ì„ ====================
        context = f"ì‚¬ìš©ì ì§ˆë¬¸: {request.message}\n\n"

        if query_data:
            # ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·
            data_text = "ì¿¼ë¦¬ ê²°ê³¼:\n"
            for i, row in enumerate(query_data[:20]):  # ìµœëŒ€ 20í–‰ë§Œ í‘œì‹œ
                data_text += f"{i+1}. {row}\n"
            context += data_text
        elif sql_query != "NO_QUERY":
            # SQLì€ ìƒì„±ë˜ì—ˆëŠ”ë° ì‹¤í–‰ ì‹¤íŒ¨ â†’ ì˜¤ë¥˜ ë©”ì‹œì§€ë§Œ í‘œì‹œ
            context += f"âš ï¸ SQL ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨. ìì„¸í•œ ë°ì´í„° ì—†ì´ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            context += f"ìƒì„±ëœ ì¿¼ë¦¬: {sql_query}\n"
        else:
            # SQLì„ ìƒì„±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° â†’ ìµœê·¼ ë¡œê·¸ ì‚¬ìš©
            context += "SQLì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ ìµœê·¼ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.\n"
            try:
                log_query = "SELECT timestamp, log_level, service, raw_message FROM logs ORDER BY timestamp DESC LIMIT 10"
                log_result = ch_client.execute(log_query)
                context += "\nìµœê·¼ ë¡œê·¸:\n"
                for row in log_result:
                    context += f"[{row[0]}] {row[1]} {row[2]}: {row[3]}\n"
            except Exception as e:
                print(f"ìµœê·¼ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ìµœê·¼ ë¡œê·¸ë„ ì¶”ê°€ (ë°°ê²½ ì •ë³´)
        recent_logs = []
        try:
            log_query = "SELECT timestamp, log_level, service, raw_message FROM logs ORDER BY timestamp DESC LIMIT 10"
            log_result = ch_client.execute(log_query)
            recent_logs = [
                f"[{row[0]}] {row[1]} {row[2]}: {row[3]}"
                for row in log_result
            ]
        except Exception as e:
            print(f"ìµœê·¼ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ==================== STEP 5: LLMì´ ìµœì¢… ë‹µë³€ ìƒì„± ====================
        print(f"ğŸ¤– Step 5: ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
        messages = [{"role": "system", "content": system_persona}]

        if request.history:
            for msg in request.history[-5:]:  # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ í¬í•¨
                messages.append({"role": msg.role, "content": msg.content})

        # ì¿¼ë¦¬ ê²°ê³¼ ë˜ëŠ” ìµœê·¼ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë¶„ì„
        final_prompt = f"""{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì¤˜.
- í†µê³„ë‚˜ ë¹ˆë„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ êµ¬ì²´ì ì¸ ìˆ«ìë¡œ ì„¤ëª…
- íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œê°€ ìˆìœ¼ë©´ ë¶„ì„ ê²°ê³¼ ì œì‹œ
- ëª…í™•í•œ í•´ì„ì„ ì œê³µ"""

        messages.append({"role": "user", "content": final_prompt})

        # LLM í˜¸ì¶œ
        model_name = llm_factory.get_model_name(provider=request.llm_provider)

        response = await client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.3,
            max_tokens=1024
        )

        ai_response = response.choices[0].message.content
        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")

        # ==================== STEP 6: Sources ìƒì„± ====================
        sources = []
        if query_data:
            # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ sourcesë¡œ ì‚¬ìš©
            for i, row in enumerate(query_data[:3]):
                sources.append(f"ë°ì´í„° í–‰ {i+1}: {row}")
        elif recent_logs:
            # Fallback: ìµœê·¼ ë¡œê·¸
            for log_entry in recent_logs[:3]:
                sources.append(log_entry)
        else:
            sources = ["ì‹¤ì‹œê°„ ë¡œê·¸ ê¸°ë°˜ ë¶„ì„"]

        # ==================== STEP 7: ë¶„ì„ ê²°ê³¼ ì €ì¥ ====================
        analysis_id = None
        try:
            llm_provider_used = request.llm_provider or settings.LLM_PROVIDER

            # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
            sql_execution_result_json = None
            if query_data:
                try:
                    # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    result_list = [list(row) if hasattr(row, '__iter__') else str(row) for row in query_data[:20]]
                    sql_execution_result_json = json.dumps(result_list, ensure_ascii=False, default=str)
                except Exception as e:
                    print(f"âš ï¸ ì¿¼ë¦¬ ê²°ê³¼ ì§ë ¬í™” ì‹¤íŒ¨: {e}")
                    sql_execution_result_json = None

            # ì „ì²´ ê³¼ì • ë¡œê·¸ë¥¼ JSONìœ¼ë¡œ
            process_steps.append({
                "step": "TOTAL_PROCESS",
                "total_duration_ms": round((time.time() - start_time) * 1000),
                "timestamp": json.loads(json.dumps({"now": str(time.time())}, default=str))["now"]
            })

            process_log_json = json.dumps(process_steps, ensure_ascii=False, default=str)

            analysis_id = ch_client.insert_analysis(
                query=request.message,
                keywords=[],  # Text-to-SQL ë°©ì‹ì—ì„œëŠ” í‚¤ì›Œë“œ ë¶ˆí•„ìš”
                log_context=context[:5000],
                llm_prompt=final_prompt,  # LLMì—ê²Œ ë³´ë‚¸ ìµœì¢… í”„ë¡¬í”„íŠ¸
                ai_response=ai_response,
                llm_provider=llm_provider_used,
                sources=sources,
                generated_sql=sql_query if sql_query != "NO_QUERY" else None,
                sql_execution_success=sql_execution_success,
                sql_execution_result=sql_execution_result_json,
                process_log=process_log_json
            )
            print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ID: {analysis_id})")
            print(f"ğŸ“Š ë¶„ì„ ê³¼ì •: {process_log_json}")
        except Exception as save_error:
            print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_error}")

        return ChatResponse(
            response=ai_response,
            sources=sources,
            analysis_id=analysis_id
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@router.get("/health")
def chat_health():
    """ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "service": "chat"}


@router.get("/history")
def get_analysis_history(limit: int = 20):
    """
    ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (Text-to-SQL ê³¼ì • í¬í•¨)

    Args:
        limit: ì¡°íšŒí•  ê°œìˆ˜ (ê¸°ë³¸ê°’: 20)

    Returns:
        ë¶„ì„ ê²°ê³¼ ëª©ë¡
    """
    from app.services.clickhouse_client import ch_client

    try:
        query = f"""
            SELECT id, timestamp, query, keywords, ai_response, llm_provider, sources,
                   generated_sql, sql_execution_success, sql_execution_result, process_log, llm_prompt
            FROM analysis_results
            ORDER BY timestamp DESC
            LIMIT {int(limit)}
        """
        results = ch_client.execute(query)

        return [
            {
                "id": str(row[0]),
                "timestamp": row[1].isoformat() if row[1] else None,
                "query": row[2],
                "keywords": row[3],
                "ai_response": row[4][:500] + "..." if len(row[4]) > 500 else row[4],
                "llm_provider": row[5],
                "sources": row[6],
                "generated_sql": row[7],
                "sql_execution_success": bool(row[8]),
                "sql_execution_result": row[9],
                "process_log": row[10],
                "llm_prompt": row[11]
            }
            for row in results
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch history: {str(e)}")


@router.get("/history/{analysis_id}")
def get_analysis_detail(analysis_id: str):
    """
    ë¶„ì„ ìƒì„¸ ì¡°íšŒ (ì „ì²´ ê³¼ì • í¬í•¨)

    Args:
        analysis_id: ë¶„ì„ ID (UUID)

    Returns:
        ë¶„ì„ ìƒì„¸ ì •ë³´ (ì§ˆë¬¸, ìƒì„±ëœ SQL, ì‹¤í–‰ ê²°ê³¼, ìµœì¢… ë‹µë³€, ê³¼ì • ë¡œê·¸)
    """
    from app.services.clickhouse_client import ch_client

    try:
        query = f"""
            SELECT id, timestamp, query, keywords, log_context, ai_response, llm_provider, sources,
                   generated_sql, sql_execution_success, sql_execution_result, process_log, llm_prompt
            FROM analysis_results
            WHERE id = '{analysis_id}'
            LIMIT 1
        """
        results = ch_client.execute(query)

        if not results:
            raise HTTPException(status_code=404, detail="Analysis not found")

        row = results[0]

        # process_log JSON íŒŒì‹± ì‹œë„
        process_log_data = None
        try:
            if row[11]:
                process_log_data = json.loads(row[11])
        except Exception:
            process_log_data = None

        # sql_execution_result JSON íŒŒì‹± ì‹œë„
        sql_result_data = None
        try:
            if row[10]:
                sql_result_data = json.loads(row[10])
        except Exception:
            sql_result_data = row[10]

        return {
            "id": str(row[0]),
            "timestamp": row[1].isoformat() if row[1] else None,
            "query": row[2],
            "keywords": row[3],
            "log_context": row[4],
            "ai_response": row[5],
            "llm_provider": row[6],
            "sources": row[7],
            "generated_sql": row[8],
            "sql_execution_success": bool(row[9]),
            "sql_execution_result": sql_result_data,
            "process_log": process_log_data,
            "llm_prompt": row[12],  # LLMì—ê²Œ ë³´ë‚¸ í”„ë¡¬í”„íŠ¸
            "analysis_summary": {
                "total_steps": len(process_log_data) if process_log_data else 0,
                "sql_used": bool(row[8]),
                "sql_success": bool(row[9])
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch analysis: {str(e)}")


@router.delete("/history/{analysis_id}")
def delete_analysis(analysis_id: str):
    """
    ë¶„ì„ íˆìŠ¤í† ë¦¬ ì‚­ì œ

    ClickHouseì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    ì£¼ì˜: ClickHouseëŠ” DELETEê°€ ë¹„ìš©ì´ í° ì‘ì—…ì´ë¯€ë¡œ
    ALTER TABLE ... DELETE ë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        analysis_id: ì‚­ì œí•  ë¶„ì„ ID (UUID)

    Returns:
        ì‚­ì œ ê²°ê³¼ ë©”ì‹œì§€
    """
    from app.services.clickhouse_client import ch_client

    try:
        # UUID í˜•ì‹ ê²€ì¦ (SQL ì¸ì ì…˜ ë°©ì§€)
        import re
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', analysis_id):
            raise HTTPException(status_code=400, detail="Invalid analysis ID format")

        # ë¨¼ì € ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        check_query = f"""
            SELECT count(*) FROM analysis_results
            WHERE id = '{analysis_id}'
        """
        check_result = ch_client.execute(check_query)

        if not check_result or check_result[0][0] == 0:
            raise HTTPException(status_code=404, detail="Analysis not found")

        # ClickHouseì—ì„œ ì‚­ì œ (ALTER TABLE ... DELETE ì‚¬ìš©)
        delete_query = f"""
            ALTER TABLE analysis_results
            DELETE WHERE id = '{analysis_id}'
        """
        ch_client.execute(delete_query)

        return {
            "success": True,
            "message": f"ë¶„ì„ ê²°ê³¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {analysis_id})"
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete analysis: {str(e)}")


@router.delete("/history")
def delete_all_analysis():
    """
    ì „ì²´ ë¶„ì„ íˆìŠ¤í† ë¦¬ ì‚­ì œ

    ClickHouseì—ì„œ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    ì£¼ì˜: ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!

    Returns:
        ì‚­ì œëœ í•­ëª© ìˆ˜
    """
    from app.services.clickhouse_client import ch_client

    try:
        # ì‚­ì œ ì „ ê°œìˆ˜ í™•ì¸
        count_query = "SELECT count(*) FROM analysis_results"
        count_result = ch_client.execute(count_query)
        total_count = count_result[0][0] if count_result else 0

        if total_count == 0:
            return {
                "success": True,
                "deleted_count": 0,
                "message": "ì‚­ì œí•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # TRUNCATE TABLE ì‚¬ìš© (ì „ì²´ ì‚­ì œì— ë” íš¨ìœ¨ì )
        truncate_query = "TRUNCATE TABLE analysis_results"
        ch_client.execute(truncate_query)

        return {
            "success": True,
            "deleted_count": total_count,
            "message": f"ì „ì²´ {total_count}ê°œì˜ ë¶„ì„ ê²°ê³¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete all analysis: {str(e)}")


# ==================== ì˜µì…˜ B: ìˆ˜ë™ Qdrant ì €ì¥ API ====================

class SaveToQdrantRequest(BaseModel):
    """Qdrant ì €ì¥ ìš”ì²­"""
    analysis_id: str = Field(..., description="ì €ì¥í•  ë¶„ì„ ID (ClickHouse)")
    title: Optional[str] = Field(default=None, description="ì‚¬ë¡€ ì œëª© (ì—†ìœ¼ë©´ ìë™ ìƒì„±)")


class SaveToQdrantResponse(BaseModel):
    """Qdrant ì €ì¥ ì‘ë‹µ"""
    success: bool = Field(..., description="ì €ì¥ ì„±ê³µ ì—¬ë¶€")
    qdrant_id: Optional[str] = Field(default=None, description="ì €ì¥ëœ Qdrant ë¬¸ì„œ ID")
    message: str = Field(..., description="ê²°ê³¼ ë©”ì‹œì§€")


@router.post("/save-to-qdrant", response_model=SaveToQdrantResponse)
async def save_analysis_to_qdrant(request: SaveToQdrantRequest):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ìˆ˜ë™ ì €ì¥ (ì˜µì…˜ B)

    ì‚¬ìš©ìê°€ ìœ ìš©í•˜ë‹¤ê³  íŒë‹¨í•œ ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ì €ì¥í•˜ì—¬
    í–¥í›„ ìœ ì‚¬ ì§ˆë¬¸ ì‹œ RAG ê²€ìƒ‰ì— í™œìš©í•©ë‹ˆë‹¤.

    Args:
        request: ì €ì¥ ìš”ì²­ (analysis_id í•„ìˆ˜)

    Returns:
        ì €ì¥ ê²°ê³¼ (success, qdrant_id, message)
    """
    from app.services.clickhouse_client import ch_client
    from app.services.rag_engine import rag_engine

    try:
        # 1. ClickHouseì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        query = f"""
            SELECT id, query, keywords, ai_response, llm_provider, sources
            FROM analysis_results
            WHERE id = '{request.analysis_id}'
            LIMIT 1
        """
        results = ch_client.execute(query)

        if not results:
            raise HTTPException(status_code=404, detail="Analysis not found")

        row = results[0]
        analysis_query = row[1]
        keywords = row[2] if row[2] else []
        ai_response = row[3]
        llm_provider = row[4]
        sources = row[5] if row[5] else []

        # 2. ì œëª© ìƒì„± (ì—†ìœ¼ë©´ ì§ˆë¬¸ ê¸°ë°˜ ìë™ ìƒì„±)
        title = request.title
        if not title:
            # ì§ˆë¬¸ì—ì„œ ì œëª© ì¶”ì¶œ (ìµœëŒ€ 50ì)
            title = f"ì±„íŒ… ë¶„ì„: {analysis_query[:50]}"
            if len(analysis_query) > 50:
                title += "..."

        # 3. Qdrantì— ì €ì¥
        qdrant_id = await rag_engine.save_incident(
            title=title,
            content=ai_response,
            incident_type="analysis",
            keywords=keywords,
            source="chat",
            metadata={
                "original_query": analysis_query,
                "llm_provider": llm_provider,
                "sources": sources,
                "analysis_id": request.analysis_id
            }
        )

        return SaveToQdrantResponse(
            success=True,
            qdrant_id=qdrant_id,
            message=f"ë¶„ì„ ê²°ê³¼ê°€ Qdrantì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {qdrant_id})"
        )

    except HTTPException:
        raise
    except Exception as e:
        return SaveToQdrantResponse(
            success=False,
            qdrant_id=None,
            message=f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/qdrant-stats")
def get_qdrant_stats():
    """
    Qdrant ì €ì¥ í˜„í™© ì¡°íšŒ

    Returns:
        ì €ì¥ëœ ì‚¬ë¡€ ìˆ˜ ë° ìƒíƒœ ì •ë³´
    """
    from app.services.rag_engine import rag_engine

    try:
        count = rag_engine.get_incident_count()
        return {
            "collection_name": rag_engine.collection_name,
            "total_documents": count,
            "vector_size": rag_engine.vector_size,
            "status": "healthy"
        }
    except Exception as e:
        return {
            "collection_name": "incident_manuals",
            "total_documents": 0,
            "vector_size": 0,
            "status": f"error: {str(e)}"
        }
