"""
@file backend/app/services/pattern_builder.py
@description
ê¸°ì¡´ ë¡œê·¸ì—ì„œ ìë™ìœ¼ë¡œ ì •ìƒ/ë¹„ì •ìƒ íŒ¨í„´ì„ ì¶”ì¶œí•˜ê³  Qdrantì— ì €ì¥í•©ë‹ˆë‹¤.
ìˆ˜ë™ ë¼ë²¨ë§ê³¼ ìë™ ë¼ë²¨ë§ APIë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. **build_patterns_from_logs()**: ClickHouse ë¡œê·¸ ì¡°íšŒ â†’ ìë™ ë¼ë²¨ë§ â†’ ë°°ì¹˜ ì„ë² ë”© â†’ Qdrant ì €ì¥
2. **_auto_label_log()**: ë‹¨ì¼ ë¡œê·¸ì˜ ìë™ ë¼ë²¨ë§ ë¡œì§
   - ERROR/CRITICAL â†’ anomaly
   - "Recog error", "Placement error" â†’ anomaly
   - INFO + í‚¤ì›Œë“œ ì—†ìŒ â†’ normal
3. **save_manual_label()**: ìˆ˜ë™ ë ˆì´ë¸” ì €ì¥
4. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™” (1000ê°œ ë‹¨ìœ„)

ì´ˆë³´ì ê°€ì´ë“œ:
- **build_patterns_from_logs()**: ìë™ íŒ¨í„´ êµ¬ì¶• íŠ¸ë¦¬ê±°
  - ClickHouseì—ì„œ ë‚ ì§œ ë²”ìœ„ì˜ ë¡œê·¸ ì¡°íšŒ
  - í…œí”Œë¦¿ë³„ë¡œ ê·¸ë£¹í™” í›„ ìë™ ë¼ë²¨ë§
  - 1000ê°œ ë°°ì¹˜ë¡œ ì„ë² ë”© ë° Qdrant ì €ì¥
- **_auto_label_log()**: ë¼ë²¨ë§ ê·œì¹™ ìˆ˜ì • ì‹œ ë³€ê²½
  - ê·œì¹™ ê¸°ë°˜ (ê·œì¹™ ìš°ì„ )
  - Anomaly keywords: "error", "exception", "timeout", "failed", "failed_recog", "failed_placement"

ì£¼ì˜:
- Qdrant ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±ë¨ (rag_engineì—ì„œ)
- ì¤‘ë³µ ë¼ë²¨ë§ ë°©ì§€ (ClickHouse log_pattern_labels ì²´í¬)
- ë°°ì¹˜ ì²˜ë¦¬ì´ë¯€ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
"""

from typing import List, Optional, Dict, Tuple, Any
from datetime import datetime
import uuid

from app.core.config import settings
from app.services.embedding_client import embedding_client
from app.services.rag_engine import rag_engine
from app.services.clickhouse_client import ch_client
from app.schemas.pattern import (
    LabelType,
    LabelSource,
    AnomalyType,
    Severity,
    BuildPatternsResponse
)


class PatternBuilder:
    """
    ë¡œê·¸ íŒ¨í„´ ìë™ êµ¬ì¶•ê¸°

    ClickHouse â†’ ìë™ ë¼ë²¨ë§ â†’ ë°°ì¹˜ ì„ë² ë”© â†’ Qdrant ì €ì¥ íŒŒì´í”„ë¼ì¸
    """

    def __init__(self):
        """ë¹Œë” ì´ˆê¸°í™”"""
        # ìë™ ë¼ë²¨ë§ ê·œì¹™
        self.anomaly_keywords = {
            "error", "exception", "timeout", "failed", "failed_recog",
            "failed_placement", "connection", "refused", "denied", "invalid"
        }
        self.batch_size = 1000

    async def build_patterns_from_logs(
        self,
        start_date: str,
        end_date: str,
        batch_size: int = 1000
    ) -> BuildPatternsResponse:
        """
        ê¸°ì¡´ ë¡œê·¸ì—ì„œ íŒ¨í„´ì„ ìë™ êµ¬ì¶•í•©ë‹ˆë‹¤.

        í”„ë¡œì„¸ìŠ¤:
        1. ClickHouseì—ì„œ ë‚ ì§œ ë²”ìœ„ì˜ ë¡œê·¸ ì¡°íšŒ (í…œí”Œë¦¿ë³„)
        2. ê° ë¡œê·¸ ìë™ ë¼ë²¨ë§ (normal/anomaly/skip)
        3. skipí•˜ì§€ ì•Šì€ ë¡œê·¸ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        4. ë°°ì¹˜ ì„ë² ë”© (embed_documents, 1000ê°œ ë‹¨ìœ„)
        5. Qdrant ì €ì¥ (normal_log_patterns / anomaly_log_patterns)
        6. ClickHouse log_pattern_labels ê¸°ë¡

        Args:
            start_date: ì‹œì‘ ë‚ ì§œ 'YYYY-MM-DD HH:MM:SS'
            end_date: ì¢…ë£Œ ë‚ ì§œ 'YYYY-MM-DD HH:MM:SS'
            batch_size: ë°°ì¹˜ í¬ê¸° (ì„ë² ë”© ë‹¨ìœ„)

        Returns:
            BuildPatternsResponse: êµ¬ì¶• ê²°ê³¼ (ì •ìƒ/ë¹„ì •ìƒ/ìŠ¤í‚µ ê°œìˆ˜, ì†Œìš” ì‹œê°„)
        """
        import time
        start_time = time.time()

        try:
            # 1. ClickHouseì—ì„œ ë¡œê·¸ ì¡°íšŒ
            print(f"ğŸ“‹ ë¡œê·¸ ì¡°íšŒ ì¤‘... ({start_date} ~ {end_date})")
            logs = ch_client.get_logs_for_pattern_building(
                start_date,
                end_date,
                limit=10000
            )

            if not logs:
                print("âš ï¸ ì¡°íšŒëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return BuildPatternsResponse(
                    normal_count=0,
                    anomaly_count=0,
                    skipped_count=0,
                    elapsed_time=0.0,
                    message="No logs found in date range"
                )

            print(f"âœ… {len(logs)}ê°œ ë¡œê·¸ ì¡°íšŒ ì™„ë£Œ")

            # 2. ìë™ ë¼ë²¨ë§
            print("ğŸ·ï¸ ìë™ ë¼ë²¨ë§ ì¤‘...")
            normal_patterns = []
            anomaly_patterns = []

            for log_row in logs:
                template_id, log_template, raw_message, log_level, service = log_row

                label, anomaly_type, severity = self._auto_label_log(
                    raw_message,
                    log_level,
                    log_template
                )

                # skipí•œ ë¡œê·¸ëŠ” ì œì™¸
                if label == "skip":
                    continue

                pattern = {
                    "template_id": template_id,
                    "log_template": log_template,
                    "representative_message": raw_message,
                    "log_level": log_level,
                    "service": service,
                    "keywords": self._extract_keywords(raw_message),
                    "label_source": "auto",
                    "sample_count": 1,
                    "first_seen": datetime.now().isoformat(),
                    "last_seen": datetime.now().isoformat()
                }

                if label == LabelType.NORMAL.value:
                    normal_patterns.append(pattern)
                elif label == LabelType.ANOMALY.value:
                    if anomaly_type:
                        pattern["anomaly_type"] = anomaly_type
                    if severity:
                        pattern["severity"] = severity
                    anomaly_patterns.append(pattern)

            skipped_count = len(logs) - len(normal_patterns) - len(anomaly_patterns)
            print(f"âœ… ë¼ë²¨ë§ ì™„ë£Œ: ì •ìƒ={len(normal_patterns)}, ë¹„ì •ìƒ={len(anomaly_patterns)}, ìŠ¤í‚µ={skipped_count}")

            # 3. ë°°ì¹˜ ì €ì¥ (Qdrant + ClickHouse)
            print("ğŸ’¾ íŒ¨í„´ ì €ì¥ ì¤‘...")
            normal_saved = 0
            anomaly_saved = 0

            # ì •ìƒ íŒ¨í„´ ë°°ì¹˜ ì²˜ë¦¬
            for i in range(0, len(normal_patterns), batch_size):
                batch = normal_patterns[i:i+batch_size]
                point_ids = await rag_engine.save_pattern_batch(
                    rag_engine.normal_patterns_collection,
                    batch
                )
                normal_saved += len(point_ids)

                # ClickHouseì— ë ˆì´ë¸” ê¸°ë¡
                for pattern, point_id in zip(batch, point_ids):
                    ch_client.insert_pattern_label(
                        template_id=pattern["template_id"],
                        label="normal",
                        label_source="auto",
                        qdrant_point_id=point_id,
                        created_by="pattern_builder"
                    )

            # ë¹„ì •ìƒ íŒ¨í„´ ë°°ì¹˜ ì²˜ë¦¬
            for i in range(0, len(anomaly_patterns), batch_size):
                batch = anomaly_patterns[i:i+batch_size]
                point_ids = await rag_engine.save_pattern_batch(
                    rag_engine.anomaly_patterns_collection,
                    batch
                )
                anomaly_saved += len(point_ids)

                # ClickHouseì— ë ˆì´ë¸” ê¸°ë¡
                for pattern, point_id in zip(batch, point_ids):
                    ch_client.insert_pattern_label(
                        template_id=pattern["template_id"],
                        label="anomaly",
                        label_source="auto",
                        qdrant_point_id=point_id,
                        anomaly_type=pattern.get("anomaly_type"),
                        severity=pattern.get("severity"),
                        created_by="pattern_builder"
                    )

            elapsed_time = time.time() - start_time

            print(f"âœ… íŒ¨í„´ ì €ì¥ ì™„ë£Œ: ì •ìƒ={normal_saved}, ë¹„ì •ìƒ={anomaly_saved}")
            print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

            return BuildPatternsResponse(
                normal_count=normal_saved,
                anomaly_count=anomaly_saved,
                skipped_count=skipped_count,
                elapsed_time=elapsed_time,
                message=f"Successfully built {normal_saved + anomaly_saved} patterns"
            )

        except Exception as e:
            print(f"âŒ íŒ¨í„´ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            raise

    def _auto_label_log(
        self,
        raw_message: str,
        log_level: str,
        log_template: str
    ) -> Tuple[str, Optional[str], Optional[str]]:
        """
        ë¡œê·¸ë¥¼ ìë™ ë¼ë²¨ë§í•©ë‹ˆë‹¤.

        ê·œì¹™:
        1. ERROR/CRITICAL â†’ anomaly (anomaly_type='level', severity ë†’ìŒ)
        2. í‚¤ì›Œë“œ ë§¤ì¹­ â†’ anomaly ë˜ëŠ” normal
        3. INFO + í‚¤ì›Œë“œ ì—†ìŒ â†’ normal (skipí•˜ì§€ ì•ŠìŒ)
        4. ê¸°íƒ€ â†’ normal

        Args:
            raw_message: ì›ë³¸ ë¡œê·¸ ë©”ì‹œì§€
            log_level: ë¡œê·¸ ë ˆë²¨ (ERROR, WARNING, INFO ë“±)
            log_template: Drain3 ë¡œê·¸ í…œí”Œë¦¿

        Returns:
            (label, anomaly_type, severity)
            - label: 'normal' | 'anomaly' | 'skip'
            - anomaly_type: 'level' | 'keyword' | None
            - severity: 'critical' | 'warning' | 'info' | None
        """
        message_lower = raw_message.lower()

        # ê·œì¹™ 1: ë ˆë²¨ ê¸°ë°˜ (ERROR/CRITICAL ì ˆëŒ€ ìš°ì„ )
        if log_level in ["ERROR", "CRITICAL"]:
            severity = "critical" if log_level == "CRITICAL" else "warning"
            return LabelType.ANOMALY.value, "level", severity

        # ê·œì¹™ 2: í‚¤ì›Œë“œ ê¸°ë°˜ (íŠ¹ì • ì—ëŸ¬ í‚¤ì›Œë“œ)
        anomaly_keywords_found = [
            kw for kw in self.anomaly_keywords
            if kw in message_lower
        ]

        if anomaly_keywords_found:
            # Recog/Placement ì—ëŸ¬ëŠ” criticalë¡œ í‘œì‹œ
            if "recog" in message_lower or "placement" in message_lower:
                return LabelType.ANOMALY.value, "keyword", "critical"
            else:
                return LabelType.ANOMALY.value, "keyword", "warning"

        # ê·œì¹™ 3: ì •ìƒ ë¡œê·¸
        # INFO + í‚¤ì›Œë“œ ì—†ìŒ â†’ ëª…í™•íˆ ì •ìƒ
        if log_level == "INFO":
            return LabelType.NORMAL.value, None, "info"

        # ê¸°íƒ€ (WARNING ë“±) â†’ ì •ìƒìœ¼ë¡œ ì²˜ë¦¬ (ê·œì¹™ ë¯¸ë§¤ì¹­)
        return LabelType.NORMAL.value, None, None

    def _extract_keywords(self, message: str) -> List[str]:
        """
        ë©”ì‹œì§€ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        ê°„ë‹¨í•œ êµ¬í˜„: ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ í›„ 3ê¸€ì ì´ìƒë§Œ í•„í„°ë§
        ì‹¤ì œë¡œëŠ” NLP ê¸°ë²• ì ìš© ê°€ëŠ¥

        Args:
            message: ë¡œê·¸ ë©”ì‹œì§€

        Returns:
            í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        words = message.split()
        keywords = [
            w.lower() for w in words
            if len(w) > 3 and not w.startswith("[") and not w.startswith("(")
        ]
        # ì¤‘ë³µ ì œê±° + ìƒìœ„ 10ê°œ
        return list(set(keywords))[:10]

    async def save_manual_label(
        self,
        template_id: int,
        label: str,
        representative_message: str,
        log_level: Optional[str] = None,
        service: Optional[str] = None,
        anomaly_type: Optional[str] = None,
        severity: Optional[str] = None,
        keywords: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Tuple[str, str]:
        """
        ìˆ˜ë™ìœ¼ë¡œ ë ˆì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.

        í”„ë¡œì„¸ìŠ¤:
        1. ë©”ì‹œì§€ ì„ë² ë”©
        2. Qdrantì— ì €ì¥ (normal_log_patterns ë˜ëŠ” anomaly_log_patterns)
        3. ClickHouse log_pattern_labels ê¸°ë¡

        Args:
            template_id: í…œí”Œë¦¿ ID
            label: 'normal' ë˜ëŠ” 'anomaly'
            representative_message: ëŒ€í‘œ ë©”ì‹œì§€
            log_level: ë¡œê·¸ ë ˆë²¨
            service: ì„œë¹„ìŠ¤ ì´ë¦„
            anomaly_type: ì´ìƒ ìœ í˜• ('level', 'keyword', 'frequency', 'manual')
            severity: ì‹¬ê°ë„ ('critical', 'warning', 'info')
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            (point_id, label_id): Qdrant Point ID, ClickHouse Label ID
        """
        try:
            # 1. ë©”ì‹œì§€ ì„ë² ë”©
            vector = await embedding_client.embed_query(representative_message)

            # 2. Qdrantì— ì €ì¥
            collection_name = (
                rag_engine.normal_patterns_collection
                if label == "normal"
                else rag_engine.anomaly_patterns_collection
            )

            point_id = str(uuid.uuid4())
            payload = {
                "template_id": template_id,
                "log_template": f"manual_{template_id}",
                "representative_message": representative_message,
                "log_level": log_level or "UNKNOWN",
                "service": service or "unknown",
                "keywords": keywords or [],
                "label_source": "manual",
                "sample_count": 1,
                "first_seen": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat()
            }

            if label == "anomaly":
                if anomaly_type:
                    payload["anomaly_type"] = anomaly_type
                if severity:
                    payload["severity"] = severity

            # Qdrant ì§ì ‘ ì €ì¥
            from qdrant_client.http import models
            rag_engine.qdrant.upsert(
                collection_name=collection_name,
                points=[
                    models.PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                ]
            )

            # 3. ClickHouseì— ê¸°ë¡
            label_id = ch_client.insert_pattern_label(
                template_id=template_id,
                label=label,
                label_source="manual",
                qdrant_point_id=point_id,
                anomaly_type=anomaly_type,
                severity=severity,
                created_by="user",
                metadata=str(metadata or {})
            )

            print(f"âœ… ìˆ˜ë™ ë ˆì´ë¸” ì €ì¥: {label_id}")
            return point_id, label_id

        except Exception as e:
            print(f"âŒ ìˆ˜ë™ ë ˆì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}")
            raise


# ì „ì—­ ë¹Œë” ì¸ìŠ¤í„´ìŠ¤
pattern_builder = PatternBuilder()
