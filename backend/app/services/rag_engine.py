"""
@file backend/app/services/rag_engine.py
@description
RAG (Retrieval-Augmented Generation) ì—”ì§„ ëª¨ë“ˆì…ë‹ˆë‹¤.
Qdrant ë²¡í„° DBì—ì„œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ClickHouseì—ì„œ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. **search_similar_incidents**: ìœ ì‚¬ ì¥ì•  ì‚¬ë¡€/ë§¤ë‰´ì–¼ ê²€ìƒ‰
2. **get_log_context**: íƒ€ì„ìŠ¤íƒ¬í”„ ì£¼ë³€ ë¡œê·¸ ì¡°íšŒ
3. **save_incident**: ì¥ì•  ì‚¬ë¡€ë¥¼ Qdrantì— ì €ì¥ (ì„ë² ë”© í¬í•¨)

ì´ˆë³´ì ê°€ì´ë“œ:
- EMBEDDING_PROVIDERì— ë”°ë¼ ë²¡í„° í¬ê¸°ê°€ ë‹¬ë¼ì§
  - local-cpu (all-MiniLM-L6-v2): 384ì°¨ì›
  - local-gpu (bge-m3): 1024ì°¨ì›
  - openai (text-embedding-3-small): 1536ì°¨ì›
- save_incident(): ë¶„ì„ ê²°ê³¼ë¥¼ ì„ë² ë”©í•˜ì—¬ Qdrantì— ì €ì¥
"""

from qdrant_client import QdrantClient
from qdrant_client.http import models
from app.core.config import settings
from app.services.embedding_client import embedding_client
from app.services.clickhouse_client import ch_client
from datetime import datetime, timedelta
from typing import List, Optional
import uuid


def _get_vector_size() -> int:
    """
    í˜„ì¬ ì„ë² ë”© í”„ë¡œë°”ì´ë”ì— ë§ëŠ” ë²¡í„° í¬ê¸° ë°˜í™˜

    Returns:
        int: ë²¡í„° ì°¨ì› ìˆ˜
    """
    provider = settings.EMBEDDING_PROVIDER
    if provider == "local-cpu":
        # sentence-transformers/all-MiniLM-L6-v2 = 384ì°¨ì›
        return 384
    elif provider == "local-gpu":
        # BAAI/bge-m3 = 1024ì°¨ì›
        return 1024
    elif provider == "openai":
        # text-embedding-3-small = 1536ì°¨ì›
        return 1536
    else:
        # ê¸°ë³¸ê°’ (all-MiniLM-L6-v2)
        return 384


class RageEngine:
    """
    RAG ì—”ì§„ í´ë˜ìŠ¤ - ë²¡í„° ê²€ìƒ‰ ë° ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
    """

    def __init__(self):
        self.qdrant = QdrantClient(host=settings.QDRANT_HOST, port=settings.QDRANT_PORT)
        self.collection_name = "incident_manuals"
        self.vector_size = _get_vector_size()
        self._init_qdrant()

    def _init_qdrant(self):
        """
        Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒì„±)
        """
        try:
            existing = self.qdrant.get_collection(self.collection_name)
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ì˜ ë²¡í„° í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ì¬ìƒì„±
            existing_size = existing.config.params.vectors.size
            if existing_size != self.vector_size:
                print(f"âš ï¸ ë²¡í„° í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€: ê¸°ì¡´={existing_size}, í•„ìš”={self.vector_size}")
                print(f"ğŸ”„ ì»¬ë ‰ì…˜ '{self.collection_name}' ì¬ìƒì„± ì¤‘...")
                self.qdrant.delete_collection(self.collection_name)
                raise Exception("Recreate collection")
        except Exception:
            # ì»¬ë ‰ì…˜ ìƒì„± (ì„ë² ë”© í”„ë¡œë°”ì´ë”ì— ë§ëŠ” ë²¡í„° í¬ê¸° ì‚¬ìš©)
            self.qdrant.create_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_size,
                    distance=models.Distance.COSINE
                ),
            )
            print(f"âœ… Qdrant ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {self.collection_name} (ë²¡í„° í¬ê¸°: {self.vector_size})")

    async def search_similar_incidents(self, query_log: str, limit: int = 3):
        """Search for similar past incidents in Qdrant."""
        query_vector = await embedding_client.embed_query(query_log)
        
        results = self.qdrant.search(
            collection_name=self.collection_name,
            query_vector=query_vector,
            limit=limit
        )
        return [{"score": hit.score, "payload": hit.payload} for hit in results]

    def get_log_context(self, timestamp, window_minutes: int = 5):
        """
        Fetch logs from ClickHouse around the anomaly timestamp.

        Args:
            timestamp: datetime ê°ì²´ ë˜ëŠ” ISO format ë¬¸ìì—´
            window_minutes: ì¡°íšŒí•  ì‹œê°„ ìœˆë„ìš° (ë¶„)

        Returns:
            í¬ë§·ëœ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        # timestampê°€ ë¬¸ìì—´ì´ë©´ datetimeìœ¼ë¡œ ë³€í™˜
        if isinstance(timestamp, str):
            try:
                timestamp = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            except ValueError:
                timestamp = datetime.now()

        start_time = timestamp - timedelta(minutes=window_minutes)
        end_time = timestamp + timedelta(minutes=window_minutes)

        # ClickHouse í˜¸í™˜ datetime í¬ë§· (YYYY-MM-DD HH:MM:SS)
        start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
        end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')

        query = f"""
        SELECT timestamp, log_level, service, raw_message
        FROM logs
        WHERE timestamp BETWEEN '{start_str}' AND '{end_str}'
        ORDER BY timestamp
        LIMIT 100
        """
        result = ch_client.client.execute(query)
        # Format as string
        context_str = "\n".join([f"[{row[0]}] {row[1]} {row[2]}: {row[3]}" for row in result])
        return context_str

    async def save_incident(
        self,
        title: str,
        content: str,
        incident_type: str = "analysis",
        keywords: Optional[List[str]] = None,
        source: str = "chat",
        metadata: Optional[dict] = None
    ) -> str:
        """
        ì¥ì•  ì‚¬ë¡€/ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ì €ì¥

        Args:
            title: ì‚¬ë¡€ ì œëª© (ì˜ˆ: "NPM/AM-06 ì¸ì‹ ì˜¤ë¥˜ ë¶„ì„")
            content: ë¶„ì„ ë‚´ìš© (LLM ì‘ë‹µ ë“±)
            incident_type: ì‚¬ë¡€ ìœ í˜• (analysis, anomaly, manual)
            keywords: ê´€ë ¨ í‚¤ì›Œë“œ ëª©ë¡
            source: ì €ì¥ ì†ŒìŠ¤ (chat, agent, manual)
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            ì €ì¥ëœ ë¬¸ì„œì˜ ID (UUID)
        """
        # 1. ì„ë² ë”© ìƒì„± (ì œëª© + ë‚´ìš© ê²°í•©)
        text_to_embed = f"{title}\n\n{content}"
        vector = await embedding_client.embed_query(text_to_embed)

        # 2. ë¬¸ì„œ ID ìƒì„±
        doc_id = str(uuid.uuid4())

        # 3. í˜ì´ë¡œë“œ êµ¬ì„±
        payload = {
            "title": title,
            "content": content,
            "type": incident_type,
            "keywords": keywords or [],
            "source": source,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        }

        # 4. Qdrantì— ì €ì¥
        self.qdrant.upsert(
            collection_name=self.collection_name,
            points=[
                models.PointStruct(
                    id=doc_id,
                    vector=vector,
                    payload=payload
                )
            ]
        )

        print(f"âœ… Qdrant ì €ì¥ ì™„ë£Œ: {title} (ID: {doc_id})")
        return doc_id

    async def save_incidents_batch(
        self,
        documents: List[dict]
    ) -> List[str]:
        """
        ì—¬ëŸ¬ ì¥ì•  ì‚¬ë¡€ë¥¼ ë°°ì¹˜ë¡œ Qdrantì— ì €ì¥

        Args:
            documents: ë¬¸ì„œ ëª©ë¡ [{"title": ..., "content": ..., ...}, ...]

        Returns:
            ì €ì¥ëœ ë¬¸ì„œ ID ëª©ë¡
        """
        if not documents:
            return []

        # 1. ëª¨ë“  ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [f"{doc['title']}\n\n{doc['content']}" for doc in documents]

        # 2. ë°°ì¹˜ ì„ë² ë”©
        vectors = await embedding_client.embed_documents(texts)

        # 3. í¬ì¸íŠ¸ êµ¬ì„±
        points = []
        doc_ids = []
        for doc, vector in zip(documents, vectors):
            doc_id = str(uuid.uuid4())
            doc_ids.append(doc_id)

            payload = {
                "title": doc.get("title", ""),
                "content": doc.get("content", ""),
                "type": doc.get("incident_type", "analysis"),
                "keywords": doc.get("keywords", []),
                "source": doc.get("source", "batch"),
                "timestamp": datetime.now().isoformat(),
                "metadata": doc.get("metadata", {})
            }

            points.append(
                models.PointStruct(
                    id=doc_id,
                    vector=vector,
                    payload=payload
                )
            )

        # 4. Qdrantì— ë°°ì¹˜ ì €ì¥
        self.qdrant.upsert(
            collection_name=self.collection_name,
            points=points
        )

        print(f"âœ… Qdrant ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(documents)}ê±´")
        return doc_ids

    def get_incident_count(self) -> int:
        """
        ì €ì¥ëœ ì‚¬ë¡€ ìˆ˜ ì¡°íšŒ

        Returns:
            ì €ì¥ëœ ë¬¸ì„œ ìˆ˜
        """
        try:
            collection_info = self.qdrant.get_collection(self.collection_name)
            return collection_info.points_count
        except Exception:
            return 0


rag_engine = RageEngine()
