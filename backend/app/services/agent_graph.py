"""
@file backend/app/services/agent_graph.py
@description
LangGraph ê¸°ë°˜ ë¡œê·¸ ë¶„ì„ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.
PyOD ì´ìƒ íƒì§€ ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ë¶„ì„ ë° ì•Œë¦¼ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. **retrieve_info**: ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ClickHouse)
2. **analyze_incident**: LLM ê¸°ë°˜ ë¶„ì„
3. **notify_admin**: Slack ì•Œë¦¼ ë°œì†¡

ì›Œí¬í”Œë¡œìš°:
retrieve_info â†’ analyze â†’ notify â†’ END

ì°¸ê³ : ë¶„ì„ ê²°ê³¼ì˜ Qdrant ì €ì¥ì€ Chat APIì—ì„œë§Œ ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import json
from typing import TypedDict, List, Optional
from langgraph.graph import StateGraph, END
from app.services.rag_engine import rag_engine
from app.services.llm_factory import llm_factory
from app.core.config import settings


class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜"""
    anomaly_data: dict           # PyOD ì´ìƒ íƒì§€ ë°ì´í„°
    log_context: str             # ClickHouse ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸
    manual_context: List[dict]   # Qdrant RAG ê²€ìƒ‰ ê²°ê³¼
    past_resolutions: List[dict] # ê³¼ê±° í•´ê²° ì‚¬ë¡€ (Qdrant incident_resolutions)
    analysis_result: str         # LLM ë¶„ì„ ê²°ê³¼
    analysis_prompt: Optional[str] # LLMì—ê²Œ ë³´ë‚¸ í”„ë¡¬í”„íŠ¸
    root_cause: Optional[str]    # ê·¼ë³¸ ì›ì¸
    recommendation: Optional[str] # ê¶Œì¥ì‚¬í•­
    process_log: Optional[str]   # ë¶„ì„ ê³¼ì • ë¡œê·¸
    is_critical: bool            # ì‹¬ê°ë„ ì—¬ë¶€
    qdrant_doc_id: Optional[str] # ì €ì¥ëœ Qdrant ë¬¸ì„œ ID

class LogAnalysisAgent:
    def __init__(self):
        self.workflow = StateGraph(AgentState)
        self._build_graph()

    def _build_graph(self):
        """
        ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±

        Flow:
        retrieve_info â†’ analyze â†’ notify â†’ save_to_db â†’ END

        ì°¸ê³ : save_to_qdrant ë…¸ë“œëŠ” ë¹„í™œì„±í™”ë¨ (ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ì˜µì…˜ë§Œ ìœ ì§€)
        """
        self.workflow.add_node("retrieve_info", self.retrieve_info)
        self.workflow.add_node("analyze", self.analyze_incident)
        # self.workflow.add_node("save_to_qdrant", self.save_to_qdrant)  # ë¹„í™œì„±í™”: ìˆ˜ë™ ì €ì¥ë§Œ ì‚¬ìš©
        self.workflow.add_node("notify", self.notify_admin)
        self.workflow.add_node("save_to_db", self.save_analysis_to_db)

        self.workflow.set_entry_point("retrieve_info")
        self.workflow.add_edge("retrieve_info", "analyze")
        self.workflow.add_edge("analyze", "notify")  # ë¶„ì„ í›„ ë°”ë¡œ ì•Œë¦¼ ë°œì†¡
        self.workflow.add_edge("notify", "save_to_db")  # ClickHouse ì €ì¥
        # self.workflow.add_edge("save_to_qdrant", "notify")  # ë¹„í™œì„±í™”
        self.workflow.add_edge("save_to_db", END)

        self.app = self.workflow.compile()

    async def retrieve_info(self, state: AgentState):
        anomaly = state["anomaly_data"]

        # 1. Get Log Context from ClickHouse (ìµœê·¼ 5ë¶„ ë¡œê·¸)
        try:
            log_context = rag_engine.get_log_context(anomaly["timestamp"])
        except Exception as e:
            print(f"âš ï¸ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            log_context = "[ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤]"

        # 2. Get Similar Manuals from Qdrant
        query_text = anomaly.get("details", "")
        try:
            manuals = await rag_engine.search_similar_incidents(query_text)
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            manuals = []

        # 3. Get Past Resolution Cases from Qdrant
        # ê³¼ê±°ì— ê°™ì€ ì¢…ë¥˜ì˜ ì´ìƒì„ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ê²€ìƒ‰
        try:
            past_resolutions = await rag_engine.search_resolutions(query_text, limit=3)
        except Exception as e:
            print(f"âš ï¸ ê³¼ê±° í•´ê²° ì‚¬ë¡€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            past_resolutions = []

        return {
            "log_context": log_context,
            "manual_context": manuals,
            "past_resolutions": past_resolutions
        }

    async def analyze_incident(self, state: AgentState):
        import time
        import os

        client = llm_factory.get_client()

        # Load System Prompt (ìƒëŒ€ ê²½ë¡œ ìˆ˜ì •)
        prompt_paths = [
            "app/core/system_prompt.md",  # backend ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰ ì‹œ
            "backend/app/core/system_prompt.md",  # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰ ì‹œ
        ]
        system_persona = "ë‹¹ì‹ ì€ NPM SMT ë§ˆìš´í„° ë¡œê·¸ ë¶„ì„ ë° ì„¤ë¹„ ë¬¸ì œ í•´ê²°ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AI SREì…ë‹ˆë‹¤."

        for prompt_path in prompt_paths:
            if os.path.exists(prompt_path):
                try:
                    with open(prompt_path, "r", encoding="utf-8") as f:
                        system_persona = f.read()
                    break
                except Exception:
                    pass

        # ==================== ë¶„ì„ ê³¼ì • ì¶”ì  ====================
        process_steps = []
        start_time = time.time()

        # ê³¼ê±° í•´ê²° ì‚¬ë¡€ í¬ë§·
        past_resolutions_text = ""
        if state.get('past_resolutions'):
            past_resolutions_text = "\n\n[ê³¼ê±° í•´ê²° ì‚¬ë¡€]\n"
            for i, resolution in enumerate(state['past_resolutions'], 1):
                payload = resolution.get('payload', {})
                past_resolutions_text += f"""
{i}. {payload.get('incident_summary', 'ì•Œ ìˆ˜ ì—†ëŠ” ì‚¬ë¡€')}
   - í•´ê²° ë°©ë²•: {payload.get('resolution', 'N/A')[:200]}...
   - í•´ê²°ì: {payload.get('resolved_by', 'N/A')}
   - ìœ ì‚¬ë„: {resolution.get('score', 0):.1%}
"""

        prompt = f"""
        [Anomaly Details]
        {state['anomaly_data']}

        [Log Context (Recent 5 mins)]
        {state['log_context']}

        [Similar Past Incidents/Manuals]
        {json.dumps(state['manual_context'], indent=2, ensure_ascii=False)}{past_resolutions_text}
        """

        # ëª¨ë¸ëª… ë™ì  ê²°ì •
        model_name = llm_factory.get_model_name()

        process_steps.append({
            "step": "LLM_ANALYSIS_START",
            "model": model_name,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        })

        try:
            response = await client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_persona},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2
            )

            analysis_result = response.choices[0].message.content

            # ë¶„ì„ ì„±ê³µ
            process_steps.append({
                "step": "LLM_ANALYSIS_COMPLETE",
                "duration_ms": round((time.time() - start_time) * 1000),
                "status": "success"
            })

            # ==================== ë¶„ì„ ê²°ê³¼ íŒŒì‹± ====================
            # AI ì‘ë‹µì—ì„œ ê·¼ë³¸ ì›ì¸ê³¼ ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
            lines = analysis_result.split('\n')
            root_cause = ""
            recommendation = ""

            capture_mode = None
            for line in lines:
                if 'ê·¼ë³¸ ì›ì¸' in line or 'Root Cause' in line or 'ì›ì¸ ë¶„ì„' in line:
                    capture_mode = "cause"
                elif 'ê¶Œì¥' in line or 'Recommendation' in line or 'í•´ê²°' in line or 'ì¡°ì¹˜' in line:
                    capture_mode = "recommendation"
                elif capture_mode == "cause" and line.strip():
                    root_cause += line + "\n"
                elif capture_mode == "recommendation" and line.strip():
                    recommendation += line + "\n"

            return {
                "analysis_result": analysis_result,
                "analysis_prompt": prompt,
                "root_cause": root_cause.strip() or analysis_result[:200],
                "recommendation": recommendation.strip() or "ì¶”ê°€ ì •ë³´ í•„ìš”",
                "process_log": json.dumps(process_steps, ensure_ascii=False, default=str)
            }
        except Exception as e:
            print(f"âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            process_steps.append({
                "step": "LLM_ANALYSIS_FAILED",
                "duration_ms": round((time.time() - start_time) * 1000),
                "error": str(e)
            })

            return {
                "analysis_result": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "analysis_prompt": prompt,
                "root_cause": "ë¶„ì„ ì‹¤íŒ¨",
                "recommendation": "ìˆ˜ë™ ê²€í†  í•„ìš”",
                "process_log": json.dumps(process_steps, ensure_ascii=False, default=str)
            }

    async def save_to_qdrant(self, state: AgentState):
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ Qdrantì— ìë™ ì €ì¥ (ì˜µì…˜ A)

        PyOD ì´ìƒ íƒì§€ â†’ LLM ë¶„ì„ ì™„ë£Œ í›„ í˜¸ì¶œë¨
        í–¥í›„ ìœ ì‚¬ ì¥ì•  ë°œìƒ ì‹œ RAG ê²€ìƒ‰ì— í™œìš©
        """
        try:
            anomaly = state["anomaly_data"]
            analysis = state["analysis_result"]

            # ì œëª© ìƒì„±: ì´ìƒ íƒì§€ ì •ë³´ ê¸°ë°˜
            title = f"ì´ìƒ íƒì§€ ë¶„ì„: {anomaly.get('details', 'ì•Œ ìˆ˜ ì—†ëŠ” ì´ìƒ')[:50]}"

            # í‚¤ì›Œë“œ ì¶”ì¶œ (anomaly_dataì—ì„œ)
            keywords = []
            if anomaly.get("service"):
                keywords.append(anomaly["service"])
            if anomaly.get("template_id"):
                keywords.append(f"template_{anomaly['template_id']}")

            # Qdrantì— ì €ì¥
            doc_id = await rag_engine.save_incident(
                title=title,
                content=analysis,
                incident_type="anomaly",
                keywords=keywords,
                source="agent",
                metadata={
                    "anomaly_score": anomaly.get("anomaly_score"),
                    "timestamp": anomaly.get("timestamp"),
                    "is_critical": state.get("is_critical", False)
                }
            )

            print(f"âœ… [Agent] Qdrant ìë™ ì €ì¥ ì™„ë£Œ: {doc_id}")
            return {"qdrant_doc_id": doc_id}

        except Exception as e:
            print(f"âš ï¸ [Agent] Qdrant ì €ì¥ ì‹¤íŒ¨: {e}")
            return {"qdrant_doc_id": None}

    async def notify_admin(self, state: AgentState):
        """
        ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ë°œì†¡ (Slack)
        """
        try:
            from app.services.notifier import notifier

            # Determine severity (simplified)
            severity = "critical" if state.get("is_critical") else "warning"

            msg = f"*ğŸš¨ [LogAi] New Anomaly Detected*\n\n{state['analysis_result'][:500]}"

            try:
                await notifier.send_slack_alert(msg, severity)
                print(f"âœ… ALARM SENT")
            except Exception as slack_error:
                print(f"âš ï¸ Slack ì•Œë¦¼ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {slack_error}")

        except Exception as e:
            print(f"âš ï¸ notify_admin ì‹¤íŒ¨: {e}")

        # LangGraphëŠ” ìµœì†Œ í•˜ë‚˜ì˜ state fieldë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        return {"is_critical": state.get("is_critical", False)}

    async def save_analysis_to_db(self, state: AgentState):
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ClickHouse anomalies í…Œì´ë¸”ì— ì €ì¥
        """
        try:
            from app.services.clickhouse_client import ch_client

            anomaly = state["anomaly_data"]
            timestamp = anomaly.get("timestamp")

            if not timestamp:
                print(f"âš ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ì–´ì„œ ì €ì¥ ìŠ¤í‚µ")
            else:
                # anomalies í…Œì´ë¸” UPDATE (timestamp ê¸°ì¤€)
                # ISO í˜•ì‹ì˜ íƒ€ì„ìŠ¤íƒí”„ë¥¼ ClickHouse DateTime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                try:
                    update_query = f"""
                        ALTER TABLE anomalies UPDATE
                            agent_analysis_prompt = '{state.get("analysis_prompt", "").replace("'", "''")}',
                            agent_analysis_result = '{state.get("analysis_result", "").replace("'", "''")}',
                            agent_root_cause = '{state.get("root_cause", "").replace("'", "''")}',
                            agent_recommendation = '{state.get("recommendation", "").replace("'", "''")}',
                            agent_process_log = '{state.get("process_log", "").replace("'", "''")}',
                            status = 'investigating'
                        WHERE timestamp = '{timestamp}'
                    """

                    ch_client.execute(update_query)
                    print(f"âœ… anomalies í…Œì´ë¸” UPDATE ì™„ë£Œ: {timestamp}")
                except Exception as update_error:
                    print(f"âš ï¸ UPDATE ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ?): {update_error}")
                    # UPDATE ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    pass

        except Exception as e:
            print(f"âš ï¸ anomalies í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}")

        # LangGraphëŠ” ìµœì†Œ í•˜ë‚˜ì˜ state fieldë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        return {"is_critical": state.get("is_critical", False)}

agent_app = LogAnalysisAgent().app
